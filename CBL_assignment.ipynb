{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbc6b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_filename = 'test.txt'\n",
    "train_filename = 'train.txt'\n",
    "\n",
    "test_data = np.loadtxt(test_filename)\n",
    "train_data = np.loadtxt(train_filename)\n",
    "\n",
    "#Convert to float32 and set the first row to x and the second row to y\n",
    "test_x = np.float32(test_data[0])\n",
    "test_y = np.float32(test_data[1])\n",
    "train_x = np.float32(train_data[0])\n",
    "train_y = np.float32(train_data[1])\n",
    "\n",
    "#Plot the result using subplot\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax1.set_title('Test data')\n",
    "ax2.set_title('Training data')\n",
    "ax1.plot(test_x, test_y)\n",
    "ax2.plot(train_x, train_y)\n",
    "\n",
    "#Save the figure\n",
    "plt.savefig('test_and_training_data_visualization.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a321ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 34.4850 - val_loss: 29.1861\n",
      "\n",
      "Epoch 00001: saving model to training_1\\cp.ckpt\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 30.7115 - val_loss: 26.2467\n",
      "\n",
      "Epoch 00002: saving model to training_1\\cp.ckpt\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 27.9465 - val_loss: 23.8215\n",
      "\n",
      "Epoch 00003: saving model to training_1\\cp.ckpt\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 25.6811 - val_loss: 22.2010\n",
      "\n",
      "Epoch 00004: saving model to training_1\\cp.ckpt\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 23.9844 - val_loss: 20.8583\n",
      "\n",
      "Epoch 00005: saving model to training_1\\cp.ckpt\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 22.2502 - val_loss: 19.9124\n",
      "\n",
      "Epoch 00006: saving model to training_1\\cp.ckpt\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 21.2664 - val_loss: 19.4067\n",
      "\n",
      "Epoch 00007: saving model to training_1\\cp.ckpt\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 20.5985 - val_loss: 18.9518\n",
      "\n",
      "Epoch 00008: saving model to training_1\\cp.ckpt\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 20.1341 - val_loss: 18.7326\n",
      "\n",
      "Epoch 00009: saving model to training_1\\cp.ckpt\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.9478 - val_loss: 18.7048\n",
      "\n",
      "Epoch 00010: saving model to training_1\\cp.ckpt\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 19.9384 - val_loss: 18.6769\n",
      "\n",
      "Epoch 00011: saving model to training_1\\cp.ckpt\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.9289 - val_loss: 18.6521\n",
      "\n",
      "Epoch 00012: saving model to training_1\\cp.ckpt\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.9193 - val_loss: 18.6303\n",
      "\n",
      "Epoch 00013: saving model to training_1\\cp.ckpt\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.9097 - val_loss: 18.6085\n",
      "\n",
      "Epoch 00014: saving model to training_1\\cp.ckpt\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 19.9000 - val_loss: 18.5933\n",
      "\n",
      "Epoch 00015: saving model to training_1\\cp.ckpt\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 19.8903 - val_loss: 18.5860\n",
      "\n",
      "Epoch 00016: saving model to training_1\\cp.ckpt\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 19.8806 - val_loss: 18.5787\n",
      "\n",
      "Epoch 00017: saving model to training_1\\cp.ckpt\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 19.8707 - val_loss: 18.5713\n",
      "\n",
      "Epoch 00018: saving model to training_1\\cp.ckpt\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.8608 - val_loss: 18.5639\n",
      "\n",
      "Epoch 00019: saving model to training_1\\cp.ckpt\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.8509 - val_loss: 18.5564\n",
      "\n",
      "Epoch 00020: saving model to training_1\\cp.ckpt\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.8409 - val_loss: 18.5489\n",
      "\n",
      "Epoch 00021: saving model to training_1\\cp.ckpt\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.8308 - val_loss: 18.5432\n",
      "\n",
      "Epoch 00022: saving model to training_1\\cp.ckpt\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.8207 - val_loss: 18.5430\n",
      "\n",
      "Epoch 00023: saving model to training_1\\cp.ckpt\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.8105 - val_loss: 18.5529\n",
      "\n",
      "Epoch 00024: saving model to training_1\\cp.ckpt\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.8003 - val_loss: 18.5654\n",
      "\n",
      "Epoch 00025: saving model to training_1\\cp.ckpt\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7899 - val_loss: 18.5835\n",
      "\n",
      "Epoch 00026: saving model to training_1\\cp.ckpt\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7796 - val_loss: 18.6043\n",
      "\n",
      "Epoch 00027: saving model to training_1\\cp.ckpt\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7691 - val_loss: 18.6272\n",
      "\n",
      "Epoch 00028: saving model to training_1\\cp.ckpt\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7586 - val_loss: 18.6559\n",
      "\n",
      "Epoch 00029: saving model to training_1\\cp.ckpt\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 19.7481 - val_loss: 18.6911\n",
      "\n",
      "Epoch 00030: saving model to training_1\\cp.ckpt\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 19.7394 - val_loss: 18.6220\n",
      "\n",
      "Epoch 00031: saving model to training_1\\cp.ckpt\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 19.7605 - val_loss: 18.6506\n",
      "\n",
      "Epoch 00032: saving model to training_1\\cp.ckpt\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 19.7499 - val_loss: 18.6840\n",
      "\n",
      "Epoch 00033: saving model to training_1\\cp.ckpt\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 19.7393 - val_loss: 18.7241\n",
      "\n",
      "Epoch 00034: saving model to training_1\\cp.ckpt\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 19.7662 - val_loss: 18.5784\n",
      "\n",
      "Epoch 00035: saving model to training_1\\cp.ckpt\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 19.7818 - val_loss: 18.5992\n",
      "\n",
      "Epoch 00036: saving model to training_1\\cp.ckpt\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 19.7714 - val_loss: 18.6203\n",
      "\n",
      "Epoch 00037: saving model to training_1\\cp.ckpt\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 19.7609 - val_loss: 18.6489\n",
      "\n",
      "Epoch 00038: saving model to training_1\\cp.ckpt\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 19.7503 - val_loss: 18.6816\n",
      "\n",
      "Epoch 00039: saving model to training_1\\cp.ckpt\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7397 - val_loss: 18.7213\n",
      "\n",
      "Epoch 00040: saving model to training_1\\cp.ckpt\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7631 - val_loss: 18.5771\n",
      "\n",
      "Epoch 00041: saving model to training_1\\cp.ckpt\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 19.7822 - val_loss: 18.5979\n",
      "\n",
      "Epoch 00042: saving model to training_1\\cp.ckpt\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 19.7718 - val_loss: 18.6189\n",
      "\n",
      "Epoch 00043: saving model to training_1\\cp.ckpt\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 19.7613 - val_loss: 18.6472\n",
      "\n",
      "Epoch 00044: saving model to training_1\\cp.ckpt\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7508 - val_loss: 18.6793\n",
      "\n",
      "Epoch 00045: saving model to training_1\\cp.ckpt\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 19.7401 - val_loss: 18.7186\n",
      "\n",
      "Epoch 00046: saving model to training_1\\cp.ckpt\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 19.7600 - val_loss: 18.5759\n",
      "\n",
      "Epoch 00047: saving model to training_1\\cp.ckpt\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7826 - val_loss: 18.5967\n",
      "\n",
      "Epoch 00048: saving model to training_1\\cp.ckpt\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7722 - val_loss: 18.6176\n",
      "\n",
      "Epoch 00049: saving model to training_1\\cp.ckpt\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7617 - val_loss: 18.6455\n",
      "\n",
      "Epoch 00050: saving model to training_1\\cp.ckpt\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7512 - val_loss: 18.6770\n",
      "\n",
      "Epoch 00051: saving model to training_1\\cp.ckpt\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7406 - val_loss: 18.7163\n",
      "\n",
      "Epoch 00052: saving model to training_1\\cp.ckpt\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7570 - val_loss: 18.5746\n",
      "\n",
      "Epoch 00053: saving model to training_1\\cp.ckpt\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 19.7830 - val_loss: 18.5954\n",
      "\n",
      "Epoch 00054: saving model to training_1\\cp.ckpt\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7726 - val_loss: 18.6163\n",
      "\n",
      "Epoch 00055: saving model to training_1\\cp.ckpt\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7621 - val_loss: 18.6438\n",
      "\n",
      "Epoch 00056: saving model to training_1\\cp.ckpt\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7516 - val_loss: 18.6747\n",
      "\n",
      "Epoch 00057: saving model to training_1\\cp.ckpt\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7410 - val_loss: 18.7140\n",
      "\n",
      "Epoch 00058: saving model to training_1\\cp.ckpt\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7539 - val_loss: 18.5734\n",
      "\n",
      "Epoch 00059: saving model to training_1\\cp.ckpt\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7834 - val_loss: 18.5942\n",
      "\n",
      "Epoch 00060: saving model to training_1\\cp.ckpt\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7730 - val_loss: 18.6150\n",
      "\n",
      "Epoch 00061: saving model to training_1\\cp.ckpt\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7626 - val_loss: 18.6421\n",
      "\n",
      "Epoch 00062: saving model to training_1\\cp.ckpt\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7520 - val_loss: 18.6724\n",
      "\n",
      "Epoch 00063: saving model to training_1\\cp.ckpt\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7414 - val_loss: 18.7116\n",
      "\n",
      "Epoch 00064: saving model to training_1\\cp.ckpt\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7512 - val_loss: 18.6369\n",
      "\n",
      "Epoch 00065: saving model to training_1\\cp.ckpt\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7539 - val_loss: 18.6656\n",
      "\n",
      "Epoch 00066: saving model to training_1\\cp.ckpt\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7433 - val_loss: 18.7045\n",
      "\n",
      "Epoch 00067: saving model to training_1\\cp.ckpt\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7470 - val_loss: 18.6316\n",
      "\n",
      "Epoch 00068: saving model to training_1\\cp.ckpt\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7557 - val_loss: 18.6603\n",
      "\n",
      "Epoch 00069: saving model to training_1\\cp.ckpt\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7451 - val_loss: 18.6973\n",
      "\n",
      "Epoch 00070: saving model to training_1\\cp.ckpt\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7428 - val_loss: 18.6264\n",
      "\n",
      "Epoch 00071: saving model to training_1\\cp.ckpt\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7575 - val_loss: 18.6551\n",
      "\n",
      "Epoch 00072: saving model to training_1\\cp.ckpt\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7469 - val_loss: 18.6901\n",
      "\n",
      "Epoch 00073: saving model to training_1\\cp.ckpt\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.7385 - val_loss: 18.6212\n",
      "\n",
      "Epoch 00074: saving model to training_1\\cp.ckpt\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7593 - val_loss: 18.6498\n",
      "\n",
      "Epoch 00075: saving model to training_1\\cp.ckpt\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7488 - val_loss: 18.6830\n",
      "\n",
      "Epoch 00076: saving model to training_1\\cp.ckpt\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7382 - val_loss: 18.7231\n",
      "\n",
      "Epoch 00077: saving model to training_1\\cp.ckpt\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 19.7654 - val_loss: 18.5777\n",
      "\n",
      "Epoch 00078: saving model to training_1\\cp.ckpt\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7806 - val_loss: 18.5984\n",
      "\n",
      "Epoch 00079: saving model to training_1\\cp.ckpt\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 19.7702 - val_loss: 18.6196\n",
      "\n",
      "Epoch 00080: saving model to training_1\\cp.ckpt\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7597 - val_loss: 18.6481\n",
      "\n",
      "Epoch 00081: saving model to training_1\\cp.ckpt\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7492 - val_loss: 18.6807\n",
      "\n",
      "Epoch 00082: saving model to training_1\\cp.ckpt\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7386 - val_loss: 18.7204\n",
      "\n",
      "Epoch 00083: saving model to training_1\\cp.ckpt\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7624 - val_loss: 18.5764\n",
      "\n",
      "Epoch 00084: saving model to training_1\\cp.ckpt\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7810 - val_loss: 18.5972\n",
      "\n",
      "Epoch 00085: saving model to training_1\\cp.ckpt\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7706 - val_loss: 18.6181\n",
      "\n",
      "Epoch 00086: saving model to training_1\\cp.ckpt\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7601 - val_loss: 18.6465\n",
      "\n",
      "Epoch 00087: saving model to training_1\\cp.ckpt\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 19.7496 - val_loss: 18.6784\n",
      "\n",
      "Epoch 00088: saving model to training_1\\cp.ckpt\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7390 - val_loss: 18.7177\n",
      "\n",
      "Epoch 00089: saving model to training_1\\cp.ckpt\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7594 - val_loss: 18.5752\n",
      "\n",
      "Epoch 00090: saving model to training_1\\cp.ckpt\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 19.7814 - val_loss: 18.5960\n",
      "\n",
      "Epoch 00091: saving model to training_1\\cp.ckpt\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 19.7710 - val_loss: 18.6168\n",
      "\n",
      "Epoch 00092: saving model to training_1\\cp.ckpt\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7606 - val_loss: 18.6448\n",
      "\n",
      "Epoch 00093: saving model to training_1\\cp.ckpt\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7500 - val_loss: 18.6762\n",
      "\n",
      "Epoch 00094: saving model to training_1\\cp.ckpt\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7394 - val_loss: 18.7154\n",
      "\n",
      "Epoch 00095: saving model to training_1\\cp.ckpt\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7564 - val_loss: 18.5740\n",
      "\n",
      "Epoch 00096: saving model to training_1\\cp.ckpt\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7818 - val_loss: 18.5947\n",
      "\n",
      "Epoch 00097: saving model to training_1\\cp.ckpt\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 19.7714 - val_loss: 18.6156\n",
      "\n",
      "Epoch 00098: saving model to training_1\\cp.ckpt\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7610 - val_loss: 18.6431\n",
      "\n",
      "Epoch 00099: saving model to training_1\\cp.ckpt\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 19.7504 - val_loss: 18.6739\n",
      "\n",
      "Epoch 00100: saving model to training_1\\cp.ckpt\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7399 - val_loss: 18.7131\n",
      "\n",
      "Epoch 00101: saving model to training_1\\cp.ckpt\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7534 - val_loss: 18.5728\n",
      "\n",
      "Epoch 00102: saving model to training_1\\cp.ckpt\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7822 - val_loss: 18.5935\n",
      "\n",
      "Epoch 00103: saving model to training_1\\cp.ckpt\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7718 - val_loss: 18.6144\n",
      "\n",
      "Epoch 00104: saving model to training_1\\cp.ckpt\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 19.7614 - val_loss: 18.6415\n",
      "\n",
      "Epoch 00105: saving model to training_1\\cp.ckpt\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 19.7509 - val_loss: 18.6717\n",
      "\n",
      "Epoch 00106: saving model to training_1\\cp.ckpt\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7403 - val_loss: 18.7108\n",
      "\n",
      "Epoch 00107: saving model to training_1\\cp.ckpt\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7505 - val_loss: 18.6363\n",
      "\n",
      "Epoch 00108: saving model to training_1\\cp.ckpt\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7527 - val_loss: 18.6649\n",
      "\n",
      "Epoch 00109: saving model to training_1\\cp.ckpt\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 19.7421 - val_loss: 18.7037\n",
      "\n",
      "Epoch 00110: saving model to training_1\\cp.ckpt\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7463 - val_loss: 18.6311\n",
      "\n",
      "Epoch 00111: saving model to training_1\\cp.ckpt\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7545 - val_loss: 18.6597\n",
      "\n",
      "Epoch 00112: saving model to training_1\\cp.ckpt\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 19.7439 - val_loss: 18.6966\n",
      "\n",
      "Epoch 00113: saving model to training_1\\cp.ckpt\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 19.7421 - val_loss: 18.6259\n",
      "\n",
      "Epoch 00114: saving model to training_1\\cp.ckpt\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7563 - val_loss: 18.6545\n",
      "\n",
      "Epoch 00115: saving model to training_1\\cp.ckpt\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7458 - val_loss: 18.6894\n",
      "\n",
      "Epoch 00116: saving model to training_1\\cp.ckpt\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 19.7379 - val_loss: 18.6207\n",
      "\n",
      "Epoch 00117: saving model to training_1\\cp.ckpt\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.7581 - val_loss: 18.6492\n",
      "\n",
      "Epoch 00118: saving model to training_1\\cp.ckpt\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7476 - val_loss: 18.6823\n",
      "\n",
      "Epoch 00119: saving model to training_1\\cp.ckpt\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7370 - val_loss: 18.7225\n",
      "\n",
      "Epoch 00120: saving model to training_1\\cp.ckpt\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7652 - val_loss: 18.5771\n",
      "\n",
      "Epoch 00121: saving model to training_1\\cp.ckpt\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7794 - val_loss: 18.5979\n",
      "\n",
      "Epoch 00122: saving model to training_1\\cp.ckpt\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7690 - val_loss: 18.6191\n",
      "\n",
      "Epoch 00123: saving model to training_1\\cp.ckpt\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7585 - val_loss: 18.6476\n",
      "\n",
      "Epoch 00124: saving model to training_1\\cp.ckpt\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7480 - val_loss: 18.6801\n",
      "\n",
      "Epoch 00125: saving model to training_1\\cp.ckpt\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7374 - val_loss: 18.7198\n",
      "\n",
      "Epoch 00126: saving model to training_1\\cp.ckpt\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7622 - val_loss: 18.5759\n",
      "\n",
      "Epoch 00127: saving model to training_1\\cp.ckpt\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7798 - val_loss: 18.5966\n",
      "\n",
      "Epoch 00128: saving model to training_1\\cp.ckpt\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7694 - val_loss: 18.6175\n",
      "\n",
      "Epoch 00129: saving model to training_1\\cp.ckpt\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7589 - val_loss: 18.6460\n",
      "\n",
      "Epoch 00130: saving model to training_1\\cp.ckpt\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7484 - val_loss: 18.6778\n",
      "\n",
      "Epoch 00131: saving model to training_1\\cp.ckpt\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7378 - val_loss: 18.7172\n",
      "\n",
      "Epoch 00132: saving model to training_1\\cp.ckpt\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7593 - val_loss: 18.5747\n",
      "\n",
      "Epoch 00133: saving model to training_1\\cp.ckpt\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7801 - val_loss: 18.5954\n",
      "\n",
      "Epoch 00134: saving model to training_1\\cp.ckpt\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7698 - val_loss: 18.6163\n",
      "\n",
      "Epoch 00135: saving model to training_1\\cp.ckpt\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7593 - val_loss: 18.6443\n",
      "\n",
      "Epoch 00136: saving model to training_1\\cp.ckpt\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7488 - val_loss: 18.6756\n",
      "\n",
      "Epoch 00137: saving model to training_1\\cp.ckpt\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7382 - val_loss: 18.7148\n",
      "\n",
      "Epoch 00138: saving model to training_1\\cp.ckpt\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7563 - val_loss: 18.5735\n",
      "\n",
      "Epoch 00139: saving model to training_1\\cp.ckpt\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 19.7805 - val_loss: 18.5942\n",
      "\n",
      "Epoch 00140: saving model to training_1\\cp.ckpt\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 19.7701 - val_loss: 18.6151\n",
      "\n",
      "Epoch 00141: saving model to training_1\\cp.ckpt\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 19.7597 - val_loss: 18.6427\n",
      "\n",
      "Epoch 00142: saving model to training_1\\cp.ckpt\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 19.7492 - val_loss: 18.6734\n",
      "\n",
      "Epoch 00143: saving model to training_1\\cp.ckpt\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 19.7386 - val_loss: 18.7126\n",
      "\n",
      "Epoch 00144: saving model to training_1\\cp.ckpt\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7534 - val_loss: 18.5723\n",
      "\n",
      "Epoch 00145: saving model to training_1\\cp.ckpt\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7809 - val_loss: 18.5930\n",
      "\n",
      "Epoch 00146: saving model to training_1\\cp.ckpt\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7705 - val_loss: 18.6138\n",
      "\n",
      "Epoch 00147: saving model to training_1\\cp.ckpt\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7601 - val_loss: 18.6411\n",
      "\n",
      "Epoch 00148: saving model to training_1\\cp.ckpt\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7496 - val_loss: 18.6712\n",
      "\n",
      "Epoch 00149: saving model to training_1\\cp.ckpt\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7390 - val_loss: 18.7104\n",
      "\n",
      "Epoch 00150: saving model to training_1\\cp.ckpt\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7505 - val_loss: 18.5711\n",
      "\n",
      "Epoch 00151: saving model to training_1\\cp.ckpt\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7813 - val_loss: 18.5918\n",
      "\n",
      "Epoch 00152: saving model to training_1\\cp.ckpt\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7709 - val_loss: 18.6126\n",
      "\n",
      "Epoch 00153: saving model to training_1\\cp.ckpt\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7605 - val_loss: 18.6395\n",
      "\n",
      "Epoch 00154: saving model to training_1\\cp.ckpt\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7500 - val_loss: 18.6692\n",
      "\n",
      "Epoch 00155: saving model to training_1\\cp.ckpt\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7394 - val_loss: 18.7082\n",
      "\n",
      "Epoch 00156: saving model to training_1\\cp.ckpt\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7487 - val_loss: 18.6343\n",
      "\n",
      "Epoch 00157: saving model to training_1\\cp.ckpt\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7518 - val_loss: 18.6629\n",
      "\n",
      "Epoch 00158: saving model to training_1\\cp.ckpt\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7412 - val_loss: 18.7011\n",
      "\n",
      "Epoch 00159: saving model to training_1\\cp.ckpt\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7445 - val_loss: 18.6291\n",
      "\n",
      "Epoch 00160: saving model to training_1\\cp.ckpt\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7536 - val_loss: 18.6577\n",
      "\n",
      "Epoch 00161: saving model to training_1\\cp.ckpt\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7431 - val_loss: 18.6940\n",
      "\n",
      "Epoch 00162: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7403 - val_loss: 18.6240\n",
      "\n",
      "Epoch 00163: saving model to training_1\\cp.ckpt\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7554 - val_loss: 18.6525\n",
      "\n",
      "Epoch 00164: saving model to training_1\\cp.ckpt\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7449 - val_loss: 18.6869\n",
      "\n",
      "Epoch 00165: saving model to training_1\\cp.ckpt\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7361 - val_loss: 18.6188\n",
      "\n",
      "Epoch 00166: saving model to training_1\\cp.ckpt\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7572 - val_loss: 18.6473\n",
      "\n",
      "Epoch 00167: saving model to training_1\\cp.ckpt\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7467 - val_loss: 18.6798\n",
      "\n",
      "Epoch 00168: saving model to training_1\\cp.ckpt\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7361 - val_loss: 18.7196\n",
      "\n",
      "Epoch 00169: saving model to training_1\\cp.ckpt\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7624 - val_loss: 18.5755\n",
      "\n",
      "Epoch 00170: saving model to training_1\\cp.ckpt\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7784 - val_loss: 18.5962\n",
      "\n",
      "Epoch 00171: saving model to training_1\\cp.ckpt\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7680 - val_loss: 18.6172\n",
      "\n",
      "Epoch 00172: saving model to training_1\\cp.ckpt\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7576 - val_loss: 18.6457\n",
      "\n",
      "Epoch 00173: saving model to training_1\\cp.ckpt\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7471 - val_loss: 18.6776\n",
      "\n",
      "Epoch 00174: saving model to training_1\\cp.ckpt\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7365 - val_loss: 18.7170\n",
      "\n",
      "Epoch 00175: saving model to training_1\\cp.ckpt\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 19.7595 - val_loss: 18.5744\n",
      "\n",
      "Epoch 00176: saving model to training_1\\cp.ckpt\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7788 - val_loss: 18.5951\n",
      "\n",
      "Epoch 00177: saving model to training_1\\cp.ckpt\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7684 - val_loss: 18.6159\n",
      "\n",
      "Epoch 00178: saving model to training_1\\cp.ckpt\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7580 - val_loss: 18.6441\n",
      "\n",
      "Epoch 00179: saving model to training_1\\cp.ckpt\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7475 - val_loss: 18.6754\n",
      "\n",
      "Epoch 00180: saving model to training_1\\cp.ckpt\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7369 - val_loss: 18.7146\n",
      "\n",
      "Epoch 00181: saving model to training_1\\cp.ckpt\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7567 - val_loss: 18.5732\n",
      "\n",
      "Epoch 00182: saving model to training_1\\cp.ckpt\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7792 - val_loss: 18.5939\n",
      "\n",
      "Epoch 00183: saving model to training_1\\cp.ckpt\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7688 - val_loss: 18.6147\n",
      "\n",
      "Epoch 00184: saving model to training_1\\cp.ckpt\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7584 - val_loss: 18.6425\n",
      "\n",
      "Epoch 00185: saving model to training_1\\cp.ckpt\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7479 - val_loss: 18.6733\n",
      "\n",
      "Epoch 00186: saving model to training_1\\cp.ckpt\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7373 - val_loss: 18.7124\n",
      "\n",
      "Epoch 00187: saving model to training_1\\cp.ckpt\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7538 - val_loss: 18.5720\n",
      "\n",
      "Epoch 00188: saving model to training_1\\cp.ckpt\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7795 - val_loss: 18.5927\n",
      "\n",
      "Epoch 00189: saving model to training_1\\cp.ckpt\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7692 - val_loss: 18.6135\n",
      "\n",
      "Epoch 00190: saving model to training_1\\cp.ckpt\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7587 - val_loss: 18.6410\n",
      "\n",
      "Epoch 00191: saving model to training_1\\cp.ckpt\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7482 - val_loss: 18.6712\n",
      "\n",
      "Epoch 00192: saving model to training_1\\cp.ckpt\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7377 - val_loss: 18.7102\n",
      "\n",
      "Epoch 00193: saving model to training_1\\cp.ckpt\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7510 - val_loss: 18.5709\n",
      "\n",
      "Epoch 00194: saving model to training_1\\cp.ckpt\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7799 - val_loss: 18.5915\n",
      "\n",
      "Epoch 00195: saving model to training_1\\cp.ckpt\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7695 - val_loss: 18.6123\n",
      "\n",
      "Epoch 00196: saving model to training_1\\cp.ckpt\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7591 - val_loss: 18.6394\n",
      "\n",
      "Epoch 00197: saving model to training_1\\cp.ckpt\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7486 - val_loss: 18.6693\n",
      "\n",
      "Epoch 00198: saving model to training_1\\cp.ckpt\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7381 - val_loss: 18.7081\n",
      "\n",
      "Epoch 00199: saving model to training_1\\cp.ckpt\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7484 - val_loss: 18.6342\n",
      "\n",
      "Epoch 00200: saving model to training_1\\cp.ckpt\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7504 - val_loss: 18.6628\n",
      "\n",
      "Epoch 00201: saving model to training_1\\cp.ckpt\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7399 - val_loss: 18.7010\n",
      "\n",
      "Epoch 00202: saving model to training_1\\cp.ckpt\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7443 - val_loss: 18.6291\n",
      "\n",
      "Epoch 00203: saving model to training_1\\cp.ckpt\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7522 - val_loss: 18.6576\n",
      "\n",
      "Epoch 00204: saving model to training_1\\cp.ckpt\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7417 - val_loss: 18.6939\n",
      "\n",
      "Epoch 00205: saving model to training_1\\cp.ckpt\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7401 - val_loss: 18.6239\n",
      "\n",
      "Epoch 00206: saving model to training_1\\cp.ckpt\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7540 - val_loss: 18.6524\n",
      "\n",
      "Epoch 00207: saving model to training_1\\cp.ckpt\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7435 - val_loss: 18.6869\n",
      "\n",
      "Epoch 00208: saving model to training_1\\cp.ckpt\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7359 - val_loss: 18.6188\n",
      "\n",
      "Epoch 00209: saving model to training_1\\cp.ckpt\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7558 - val_loss: 18.6473\n",
      "\n",
      "Epoch 00210: saving model to training_1\\cp.ckpt\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7453 - val_loss: 18.6798\n",
      "\n",
      "Epoch 00211: saving model to training_1\\cp.ckpt\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7347 - val_loss: 18.7198\n",
      "\n",
      "Epoch 00212: saving model to training_1\\cp.ckpt\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7631 - val_loss: 18.5753\n",
      "\n",
      "Epoch 00213: saving model to training_1\\cp.ckpt\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7770 - val_loss: 18.5960\n",
      "\n",
      "Epoch 00214: saving model to training_1\\cp.ckpt\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7666 - val_loss: 18.6172\n",
      "\n",
      "Epoch 00215: saving model to training_1\\cp.ckpt\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7562 - val_loss: 18.6457\n",
      "\n",
      "Epoch 00216: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7457 - val_loss: 18.6777\n",
      "\n",
      "Epoch 00217: saving model to training_1\\cp.ckpt\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7351 - val_loss: 18.7173\n",
      "\n",
      "Epoch 00218: saving model to training_1\\cp.ckpt\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7603 - val_loss: 18.5742\n",
      "\n",
      "Epoch 00219: saving model to training_1\\cp.ckpt\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7773 - val_loss: 18.5949\n",
      "\n",
      "Epoch 00220: saving model to training_1\\cp.ckpt\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7670 - val_loss: 18.6157\n",
      "\n",
      "Epoch 00221: saving model to training_1\\cp.ckpt\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7566 - val_loss: 18.6441\n",
      "\n",
      "Epoch 00222: saving model to training_1\\cp.ckpt\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7461 - val_loss: 18.6756\n",
      "\n",
      "Epoch 00223: saving model to training_1\\cp.ckpt\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7355 - val_loss: 18.7148\n",
      "\n",
      "Epoch 00224: saving model to training_1\\cp.ckpt\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7575 - val_loss: 18.5730\n",
      "\n",
      "Epoch 00225: saving model to training_1\\cp.ckpt\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7777 - val_loss: 18.5937\n",
      "\n",
      "Epoch 00226: saving model to training_1\\cp.ckpt\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7673 - val_loss: 18.6145\n",
      "\n",
      "Epoch 00227: saving model to training_1\\cp.ckpt\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 19.7569 - val_loss: 18.6426\n",
      "\n",
      "Epoch 00228: saving model to training_1\\cp.ckpt\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7464 - val_loss: 18.6735\n",
      "\n",
      "Epoch 00229: saving model to training_1\\cp.ckpt\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7359 - val_loss: 18.7125\n",
      "\n",
      "Epoch 00230: saving model to training_1\\cp.ckpt\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7547 - val_loss: 18.5719\n",
      "\n",
      "Epoch 00231: saving model to training_1\\cp.ckpt\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7781 - val_loss: 18.5926\n",
      "\n",
      "Epoch 00232: saving model to training_1\\cp.ckpt\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 19.7677 - val_loss: 18.6133\n",
      "\n",
      "Epoch 00233: saving model to training_1\\cp.ckpt\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7573 - val_loss: 18.6410\n",
      "\n",
      "Epoch 00234: saving model to training_1\\cp.ckpt\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 19.7468 - val_loss: 18.6715\n",
      "\n",
      "Epoch 00235: saving model to training_1\\cp.ckpt\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 19.7362 - val_loss: 18.7104\n",
      "\n",
      "Epoch 00236: saving model to training_1\\cp.ckpt\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 19.7519 - val_loss: 18.5708\n",
      "\n",
      "Epoch 00237: saving model to training_1\\cp.ckpt\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7784 - val_loss: 18.5914\n",
      "\n",
      "Epoch 00238: saving model to training_1\\cp.ckpt\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7681 - val_loss: 18.6122\n",
      "\n",
      "Epoch 00239: saving model to training_1\\cp.ckpt\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7577 - val_loss: 18.6395\n",
      "\n",
      "Epoch 00240: saving model to training_1\\cp.ckpt\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7472 - val_loss: 18.6696\n",
      "\n",
      "Epoch 00241: saving model to training_1\\cp.ckpt\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7366 - val_loss: 18.7083\n",
      "\n",
      "Epoch 00242: saving model to training_1\\cp.ckpt\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7491 - val_loss: 18.5696\n",
      "\n",
      "Epoch 00243: saving model to training_1\\cp.ckpt\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7788 - val_loss: 18.5903\n",
      "\n",
      "Epoch 00244: saving model to training_1\\cp.ckpt\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 19.7684 - val_loss: 18.6110\n",
      "\n",
      "Epoch 00245: saving model to training_1\\cp.ckpt\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7580 - val_loss: 18.6380\n",
      "\n",
      "Epoch 00246: saving model to training_1\\cp.ckpt\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7475 - val_loss: 18.6677\n",
      "\n",
      "Epoch 00247: saving model to training_1\\cp.ckpt\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7370 - val_loss: 18.7062\n",
      "\n",
      "Epoch 00248: saving model to training_1\\cp.ckpt\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7471 - val_loss: 18.6328\n",
      "\n",
      "Epoch 00249: saving model to training_1\\cp.ckpt\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 19.7493 - val_loss: 18.6614\n",
      "\n",
      "Epoch 00250: saving model to training_1\\cp.ckpt\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 19.7388 - val_loss: 18.6992\n",
      "\n",
      "Epoch 00251: saving model to training_1\\cp.ckpt\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7429 - val_loss: 18.6277\n",
      "\n",
      "Epoch 00252: saving model to training_1\\cp.ckpt\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 19.7511 - val_loss: 18.6562\n",
      "\n",
      "Epoch 00253: saving model to training_1\\cp.ckpt\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7406 - val_loss: 18.6921\n",
      "\n",
      "Epoch 00254: saving model to training_1\\cp.ckpt\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7388 - val_loss: 18.6226\n",
      "\n",
      "Epoch 00255: saving model to training_1\\cp.ckpt\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7529 - val_loss: 18.6511\n",
      "\n",
      "Epoch 00256: saving model to training_1\\cp.ckpt\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7424 - val_loss: 18.6851\n",
      "\n",
      "Epoch 00257: saving model to training_1\\cp.ckpt\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7346 - val_loss: 18.6175\n",
      "\n",
      "Epoch 00258: saving model to training_1\\cp.ckpt\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7547 - val_loss: 18.6459\n",
      "\n",
      "Epoch 00259: saving model to training_1\\cp.ckpt\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7442 - val_loss: 18.6781\n",
      "\n",
      "Epoch 00260: saving model to training_1\\cp.ckpt\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7336 - val_loss: 18.7180\n",
      "\n",
      "Epoch 00261: saving model to training_1\\cp.ckpt\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 19.7614 - val_loss: 18.5742\n",
      "\n",
      "Epoch 00262: saving model to training_1\\cp.ckpt\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7758 - val_loss: 18.5948\n",
      "\n",
      "Epoch 00263: saving model to training_1\\cp.ckpt\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7655 - val_loss: 18.6160\n",
      "\n",
      "Epoch 00264: saving model to training_1\\cp.ckpt\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7550 - val_loss: 18.6444\n",
      "\n",
      "Epoch 00265: saving model to training_1\\cp.ckpt\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7446 - val_loss: 18.6760\n",
      "\n",
      "Epoch 00266: saving model to training_1\\cp.ckpt\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7340 - val_loss: 18.7155\n",
      "\n",
      "Epoch 00267: saving model to training_1\\cp.ckpt\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7587 - val_loss: 18.5731\n",
      "\n",
      "Epoch 00268: saving model to training_1\\cp.ckpt\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7762 - val_loss: 18.5937\n",
      "\n",
      "Epoch 00269: saving model to training_1\\cp.ckpt\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7658 - val_loss: 18.6145\n",
      "\n",
      "Epoch 00270: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7554 - val_loss: 18.6429\n",
      "\n",
      "Epoch 00271: saving model to training_1\\cp.ckpt\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7449 - val_loss: 18.6740\n",
      "\n",
      "Epoch 00272: saving model to training_1\\cp.ckpt\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7344 - val_loss: 18.7131\n",
      "\n",
      "Epoch 00273: saving model to training_1\\cp.ckpt\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7560 - val_loss: 18.5720\n",
      "\n",
      "Epoch 00274: saving model to training_1\\cp.ckpt\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 19.7765 - val_loss: 18.5926\n",
      "\n",
      "Epoch 00275: saving model to training_1\\cp.ckpt\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7662 - val_loss: 18.6133\n",
      "\n",
      "Epoch 00276: saving model to training_1\\cp.ckpt\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7558 - val_loss: 18.6414\n",
      "\n",
      "Epoch 00277: saving model to training_1\\cp.ckpt\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7453 - val_loss: 18.6721\n",
      "\n",
      "Epoch 00278: saving model to training_1\\cp.ckpt\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7347 - val_loss: 18.7109\n",
      "\n",
      "Epoch 00279: saving model to training_1\\cp.ckpt\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7533 - val_loss: 18.5708\n",
      "\n",
      "Epoch 00280: saving model to training_1\\cp.ckpt\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7769 - val_loss: 18.5914\n",
      "\n",
      "Epoch 00281: saving model to training_1\\cp.ckpt\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7665 - val_loss: 18.6122\n",
      "\n",
      "Epoch 00282: saving model to training_1\\cp.ckpt\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7561 - val_loss: 18.6399\n",
      "\n",
      "Epoch 00283: saving model to training_1\\cp.ckpt\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7456 - val_loss: 18.6703\n",
      "\n",
      "Epoch 00284: saving model to training_1\\cp.ckpt\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 19.7351 - val_loss: 18.7088\n",
      "\n",
      "Epoch 00285: saving model to training_1\\cp.ckpt\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 19.7505 - val_loss: 18.5697\n",
      "\n",
      "Epoch 00286: saving model to training_1\\cp.ckpt\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7772 - val_loss: 18.5903\n",
      "\n",
      "Epoch 00287: saving model to training_1\\cp.ckpt\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 19.7669 - val_loss: 18.6111\n",
      "\n",
      "Epoch 00288: saving model to training_1\\cp.ckpt\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7565 - val_loss: 18.6383\n",
      "\n",
      "Epoch 00289: saving model to training_1\\cp.ckpt\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7460 - val_loss: 18.6684\n",
      "\n",
      "Epoch 00290: saving model to training_1\\cp.ckpt\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7355 - val_loss: 18.7068\n",
      "\n",
      "Epoch 00291: saving model to training_1\\cp.ckpt\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7479 - val_loss: 18.5686\n",
      "\n",
      "Epoch 00292: saving model to training_1\\cp.ckpt\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7775 - val_loss: 18.5892\n",
      "\n",
      "Epoch 00293: saving model to training_1\\cp.ckpt\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.7672 - val_loss: 18.6099\n",
      "\n",
      "Epoch 00294: saving model to training_1\\cp.ckpt\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7568 - val_loss: 18.6369\n",
      "\n",
      "Epoch 00295: saving model to training_1\\cp.ckpt\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 19.7463 - val_loss: 18.6665\n",
      "\n",
      "Epoch 00296: saving model to training_1\\cp.ckpt\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7358 - val_loss: 18.7047\n",
      "\n",
      "Epoch 00297: saving model to training_1\\cp.ckpt\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7460 - val_loss: 18.6318\n",
      "\n",
      "Epoch 00298: saving model to training_1\\cp.ckpt\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7481 - val_loss: 18.6602\n",
      "\n",
      "Epoch 00299: saving model to training_1\\cp.ckpt\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7376 - val_loss: 18.6977\n",
      "\n",
      "Epoch 00300: saving model to training_1\\cp.ckpt\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 19.7419 - val_loss: 18.6267\n",
      "\n",
      "Epoch 00301: saving model to training_1\\cp.ckpt\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7499 - val_loss: 18.6551\n",
      "\n",
      "Epoch 00302: saving model to training_1\\cp.ckpt\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 19.7394 - val_loss: 18.6907\n",
      "\n",
      "Epoch 00303: saving model to training_1\\cp.ckpt\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7377 - val_loss: 18.6216\n",
      "\n",
      "Epoch 00304: saving model to training_1\\cp.ckpt\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7517 - val_loss: 18.6500\n",
      "\n",
      "Epoch 00305: saving model to training_1\\cp.ckpt\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7412 - val_loss: 18.6838\n",
      "\n",
      "Epoch 00306: saving model to training_1\\cp.ckpt\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7336 - val_loss: 18.6165\n",
      "\n",
      "Epoch 00307: saving model to training_1\\cp.ckpt\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7535 - val_loss: 18.6449\n",
      "\n",
      "Epoch 00308: saving model to training_1\\cp.ckpt\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7430 - val_loss: 18.6768\n",
      "\n",
      "Epoch 00309: saving model to training_1\\cp.ckpt\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7324 - val_loss: 18.7166\n",
      "\n",
      "Epoch 00310: saving model to training_1\\cp.ckpt\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7604 - val_loss: 18.5732\n",
      "\n",
      "Epoch 00311: saving model to training_1\\cp.ckpt\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 19.7746 - val_loss: 18.5939\n",
      "\n",
      "Epoch 00312: saving model to training_1\\cp.ckpt\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.76 - 0s 101ms/step - loss: 19.7642 - val_loss: 18.6150\n",
      "\n",
      "Epoch 00313: saving model to training_1\\cp.ckpt\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7538 - val_loss: 18.6434\n",
      "\n",
      "Epoch 00314: saving model to training_1\\cp.ckpt\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7433 - val_loss: 18.6749\n",
      "\n",
      "Epoch 00315: saving model to training_1\\cp.ckpt\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7328 - val_loss: 18.7142\n",
      "\n",
      "Epoch 00316: saving model to training_1\\cp.ckpt\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.7577 - val_loss: 18.5722\n",
      "\n",
      "Epoch 00317: saving model to training_1\\cp.ckpt\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7749 - val_loss: 18.5928\n",
      "\n",
      "Epoch 00318: saving model to training_1\\cp.ckpt\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7645 - val_loss: 18.6136\n",
      "\n",
      "Epoch 00319: saving model to training_1\\cp.ckpt\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 19.7541 - val_loss: 18.6419\n",
      "\n",
      "Epoch 00320: saving model to training_1\\cp.ckpt\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 19.7437 - val_loss: 18.6730\n",
      "\n",
      "Epoch 00321: saving model to training_1\\cp.ckpt\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7331 - val_loss: 18.7118\n",
      "\n",
      "Epoch 00322: saving model to training_1\\cp.ckpt\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7551 - val_loss: 18.5711\n",
      "\n",
      "Epoch 00323: saving model to training_1\\cp.ckpt\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7752 - val_loss: 18.5917\n",
      "\n",
      "Epoch 00324: saving model to training_1\\cp.ckpt\n",
      "Epoch 325/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7649 - val_loss: 18.6124\n",
      "\n",
      "Epoch 00325: saving model to training_1\\cp.ckpt\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7545 - val_loss: 18.6404\n",
      "\n",
      "Epoch 00326: saving model to training_1\\cp.ckpt\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7440 - val_loss: 18.6712\n",
      "\n",
      "Epoch 00327: saving model to training_1\\cp.ckpt\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7335 - val_loss: 18.7097\n",
      "\n",
      "Epoch 00328: saving model to training_1\\cp.ckpt\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7524 - val_loss: 18.5700\n",
      "\n",
      "Epoch 00329: saving model to training_1\\cp.ckpt\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7755 - val_loss: 18.5906\n",
      "\n",
      "Epoch 00330: saving model to training_1\\cp.ckpt\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7652 - val_loss: 18.6113\n",
      "\n",
      "Epoch 00331: saving model to training_1\\cp.ckpt\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7548 - val_loss: 18.6390\n",
      "\n",
      "Epoch 00332: saving model to training_1\\cp.ckpt\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7444 - val_loss: 18.6694\n",
      "\n",
      "Epoch 00333: saving model to training_1\\cp.ckpt\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7338 - val_loss: 18.7077\n",
      "\n",
      "Epoch 00334: saving model to training_1\\cp.ckpt\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7498 - val_loss: 18.5689\n",
      "\n",
      "Epoch 00335: saving model to training_1\\cp.ckpt\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 19.7759 - val_loss: 18.5895\n",
      "\n",
      "Epoch 00336: saving model to training_1\\cp.ckpt\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7655 - val_loss: 18.6102\n",
      "\n",
      "Epoch 00337: saving model to training_1\\cp.ckpt\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7552 - val_loss: 18.6375\n",
      "\n",
      "Epoch 00338: saving model to training_1\\cp.ckpt\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7447 - val_loss: 18.6676\n",
      "\n",
      "Epoch 00339: saving model to training_1\\cp.ckpt\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7342 - val_loss: 18.7057\n",
      "\n",
      "Epoch 00340: saving model to training_1\\cp.ckpt\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7472 - val_loss: 18.5678\n",
      "\n",
      "Epoch 00341: saving model to training_1\\cp.ckpt\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7762 - val_loss: 18.5884\n",
      "\n",
      "Epoch 00342: saving model to training_1\\cp.ckpt\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7659 - val_loss: 18.6091\n",
      "\n",
      "Epoch 00343: saving model to training_1\\cp.ckpt\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7555 - val_loss: 18.6361\n",
      "\n",
      "Epoch 00344: saving model to training_1\\cp.ckpt\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7450 - val_loss: 18.6658\n",
      "\n",
      "Epoch 00345: saving model to training_1\\cp.ckpt\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7345 - val_loss: 18.7037\n",
      "\n",
      "Epoch 00346: saving model to training_1\\cp.ckpt\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7451 - val_loss: 18.6310\n",
      "\n",
      "Epoch 00347: saving model to training_1\\cp.ckpt\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7468 - val_loss: 18.6594\n",
      "\n",
      "Epoch 00348: saving model to training_1\\cp.ckpt\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7363 - val_loss: 18.6968\n",
      "\n",
      "Epoch 00349: saving model to training_1\\cp.ckpt\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7410 - val_loss: 18.6259\n",
      "\n",
      "Epoch 00350: saving model to training_1\\cp.ckpt\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7486 - val_loss: 18.6543\n",
      "\n",
      "Epoch 00351: saving model to training_1\\cp.ckpt\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7381 - val_loss: 18.6898\n",
      "\n",
      "Epoch 00352: saving model to training_1\\cp.ckpt\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7369 - val_loss: 18.6209\n",
      "\n",
      "Epoch 00353: saving model to training_1\\cp.ckpt\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7504 - val_loss: 18.6492\n",
      "\n",
      "Epoch 00354: saving model to training_1\\cp.ckpt\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7399 - val_loss: 18.6828\n",
      "\n",
      "Epoch 00355: saving model to training_1\\cp.ckpt\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7328 - val_loss: 18.6158\n",
      "\n",
      "Epoch 00356: saving model to training_1\\cp.ckpt\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7521 - val_loss: 18.6441\n",
      "\n",
      "Epoch 00357: saving model to training_1\\cp.ckpt\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7416 - val_loss: 18.6760\n",
      "\n",
      "Epoch 00358: saving model to training_1\\cp.ckpt\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7311 - val_loss: 18.7157\n",
      "\n",
      "Epoch 00359: saving model to training_1\\cp.ckpt\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7599 - val_loss: 18.5725\n",
      "\n",
      "Epoch 00360: saving model to training_1\\cp.ckpt\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7732 - val_loss: 18.5931\n",
      "\n",
      "Epoch 00361: saving model to training_1\\cp.ckpt\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7628 - val_loss: 18.6144\n",
      "\n",
      "Epoch 00362: saving model to training_1\\cp.ckpt\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7524 - val_loss: 18.6427\n",
      "\n",
      "Epoch 00363: saving model to training_1\\cp.ckpt\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7420 - val_loss: 18.6742\n",
      "\n",
      "Epoch 00364: saving model to training_1\\cp.ckpt\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7314 - val_loss: 18.7134\n",
      "\n",
      "Epoch 00365: saving model to training_1\\cp.ckpt\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7573 - val_loss: 18.5715\n",
      "\n",
      "Epoch 00366: saving model to training_1\\cp.ckpt\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7735 - val_loss: 18.5920\n",
      "\n",
      "Epoch 00367: saving model to training_1\\cp.ckpt\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7632 - val_loss: 18.6129\n",
      "\n",
      "Epoch 00368: saving model to training_1\\cp.ckpt\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7528 - val_loss: 18.6413\n",
      "\n",
      "Epoch 00369: saving model to training_1\\cp.ckpt\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7423 - val_loss: 18.6725\n",
      "\n",
      "Epoch 00370: saving model to training_1\\cp.ckpt\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7318 - val_loss: 18.7111\n",
      "\n",
      "Epoch 00371: saving model to training_1\\cp.ckpt\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7547 - val_loss: 18.5704\n",
      "\n",
      "Epoch 00372: saving model to training_1\\cp.ckpt\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7738 - val_loss: 18.5910\n",
      "\n",
      "Epoch 00373: saving model to training_1\\cp.ckpt\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7635 - val_loss: 18.6117\n",
      "\n",
      "Epoch 00374: saving model to training_1\\cp.ckpt\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7531 - val_loss: 18.6398\n",
      "\n",
      "Epoch 00375: saving model to training_1\\cp.ckpt\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7426 - val_loss: 18.6707\n",
      "\n",
      "Epoch 00376: saving model to training_1\\cp.ckpt\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7321 - val_loss: 18.7090\n",
      "\n",
      "Epoch 00377: saving model to training_1\\cp.ckpt\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7521 - val_loss: 18.5694\n",
      "\n",
      "Epoch 00378: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7741 - val_loss: 18.5899\n",
      "\n",
      "Epoch 00379: saving model to training_1\\cp.ckpt\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7638 - val_loss: 18.6106\n",
      "\n",
      "Epoch 00380: saving model to training_1\\cp.ckpt\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7534 - val_loss: 18.6384\n",
      "\n",
      "Epoch 00381: saving model to training_1\\cp.ckpt\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7430 - val_loss: 18.6689\n",
      "\n",
      "Epoch 00382: saving model to training_1\\cp.ckpt\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7325 - val_loss: 18.7070\n",
      "\n",
      "Epoch 00383: saving model to training_1\\cp.ckpt\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7496 - val_loss: 18.5683\n",
      "\n",
      "Epoch 00384: saving model to training_1\\cp.ckpt\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7744 - val_loss: 18.5888\n",
      "\n",
      "Epoch 00385: saving model to training_1\\cp.ckpt\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7641 - val_loss: 18.6095\n",
      "\n",
      "Epoch 00386: saving model to training_1\\cp.ckpt\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7537 - val_loss: 18.6370\n",
      "\n",
      "Epoch 00387: saving model to training_1\\cp.ckpt\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7433 - val_loss: 18.6671\n",
      "\n",
      "Epoch 00388: saving model to training_1\\cp.ckpt\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7328 - val_loss: 18.7051\n",
      "\n",
      "Epoch 00389: saving model to training_1\\cp.ckpt\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7471 - val_loss: 18.5673\n",
      "\n",
      "Epoch 00390: saving model to training_1\\cp.ckpt\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7747 - val_loss: 18.5878\n",
      "\n",
      "Epoch 00391: saving model to training_1\\cp.ckpt\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7644 - val_loss: 18.6084\n",
      "\n",
      "Epoch 00392: saving model to training_1\\cp.ckpt\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7541 - val_loss: 18.6356\n",
      "\n",
      "Epoch 00393: saving model to training_1\\cp.ckpt\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7436 - val_loss: 18.6654\n",
      "\n",
      "Epoch 00394: saving model to training_1\\cp.ckpt\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7331 - val_loss: 18.7031\n",
      "\n",
      "Epoch 00395: saving model to training_1\\cp.ckpt\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 19.7445 - val_loss: 18.6305\n",
      "\n",
      "Epoch 00396: saving model to training_1\\cp.ckpt\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7454 - val_loss: 18.6590\n",
      "\n",
      "Epoch 00397: saving model to training_1\\cp.ckpt\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7349 - val_loss: 18.6962\n",
      "\n",
      "Epoch 00398: saving model to training_1\\cp.ckpt\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7404 - val_loss: 18.6255\n",
      "\n",
      "Epoch 00399: saving model to training_1\\cp.ckpt\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7471 - val_loss: 18.6538\n",
      "\n",
      "Epoch 00400: saving model to training_1\\cp.ckpt\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7367 - val_loss: 18.6893\n",
      "\n",
      "Epoch 00401: saving model to training_1\\cp.ckpt\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 19.7364 - val_loss: 18.6204\n",
      "\n",
      "Epoch 00402: saving model to training_1\\cp.ckpt\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 19.7489 - val_loss: 18.6488\n",
      "\n",
      "Epoch 00403: saving model to training_1\\cp.ckpt\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 19.7384 - val_loss: 18.6824\n",
      "\n",
      "Epoch 00404: saving model to training_1\\cp.ckpt\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7323 - val_loss: 18.6154\n",
      "\n",
      "Epoch 00405: saving model to training_1\\cp.ckpt\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7507 - val_loss: 18.6437\n",
      "\n",
      "Epoch 00406: saving model to training_1\\cp.ckpt\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7402 - val_loss: 18.6757\n",
      "\n",
      "Epoch 00407: saving model to training_1\\cp.ckpt\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7297 - val_loss: 18.7154\n",
      "\n",
      "Epoch 00408: saving model to training_1\\cp.ckpt\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7600 - val_loss: 18.5720\n",
      "\n",
      "Epoch 00409: saving model to training_1\\cp.ckpt\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7717 - val_loss: 18.5926\n",
      "\n",
      "Epoch 00410: saving model to training_1\\cp.ckpt\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7614 - val_loss: 18.6140\n",
      "\n",
      "Epoch 00411: saving model to training_1\\cp.ckpt\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7510 - val_loss: 18.6423\n",
      "\n",
      "Epoch 00412: saving model to training_1\\cp.ckpt\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7405 - val_loss: 18.6740\n",
      "\n",
      "Epoch 00413: saving model to training_1\\cp.ckpt\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7300 - val_loss: 18.7131\n",
      "\n",
      "Epoch 00414: saving model to training_1\\cp.ckpt\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7575 - val_loss: 18.5710\n",
      "\n",
      "Epoch 00415: saving model to training_1\\cp.ckpt\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7720 - val_loss: 18.5915\n",
      "\n",
      "Epoch 00416: saving model to training_1\\cp.ckpt\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7617 - val_loss: 18.6126\n",
      "\n",
      "Epoch 00417: saving model to training_1\\cp.ckpt\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7513 - val_loss: 18.6409\n",
      "\n",
      "Epoch 00418: saving model to training_1\\cp.ckpt\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7408 - val_loss: 18.6722\n",
      "\n",
      "Epoch 00419: saving model to training_1\\cp.ckpt\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7303 - val_loss: 18.7109\n",
      "\n",
      "Epoch 00420: saving model to training_1\\cp.ckpt\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7549 - val_loss: 18.5700\n",
      "\n",
      "Epoch 00421: saving model to training_1\\cp.ckpt\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7723 - val_loss: 18.5905\n",
      "\n",
      "Epoch 00422: saving model to training_1\\cp.ckpt\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7620 - val_loss: 18.6113\n",
      "\n",
      "Epoch 00423: saving model to training_1\\cp.ckpt\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7516 - val_loss: 18.6395\n",
      "\n",
      "Epoch 00424: saving model to training_1\\cp.ckpt\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7412 - val_loss: 18.6705\n",
      "\n",
      "Epoch 00425: saving model to training_1\\cp.ckpt\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7306 - val_loss: 18.7086\n",
      "\n",
      "Epoch 00426: saving model to training_1\\cp.ckpt\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7525 - val_loss: 18.5689\n",
      "\n",
      "Epoch 00427: saving model to training_1\\cp.ckpt\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7726 - val_loss: 18.5895\n",
      "\n",
      "Epoch 00428: saving model to training_1\\cp.ckpt\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7623 - val_loss: 18.6101\n",
      "\n",
      "Epoch 00429: saving model to training_1\\cp.ckpt\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7519 - val_loss: 18.6381\n",
      "\n",
      "Epoch 00430: saving model to training_1\\cp.ckpt\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7415 - val_loss: 18.6688\n",
      "\n",
      "Epoch 00431: saving model to training_1\\cp.ckpt\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7310 - val_loss: 18.7067\n",
      "\n",
      "Epoch 00432: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7500 - val_loss: 18.5679\n",
      "\n",
      "Epoch 00433: saving model to training_1\\cp.ckpt\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7729 - val_loss: 18.5884\n",
      "\n",
      "Epoch 00434: saving model to training_1\\cp.ckpt\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7626 - val_loss: 18.6091\n",
      "\n",
      "Epoch 00435: saving model to training_1\\cp.ckpt\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7522 - val_loss: 18.6367\n",
      "\n",
      "Epoch 00436: saving model to training_1\\cp.ckpt\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7418 - val_loss: 18.6671\n",
      "\n",
      "Epoch 00437: saving model to training_1\\cp.ckpt\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7313 - val_loss: 18.7048\n",
      "\n",
      "Epoch 00438: saving model to training_1\\cp.ckpt\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7475 - val_loss: 18.5669\n",
      "\n",
      "Epoch 00439: saving model to training_1\\cp.ckpt\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7732 - val_loss: 18.5874\n",
      "\n",
      "Epoch 00440: saving model to training_1\\cp.ckpt\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7629 - val_loss: 18.6080\n",
      "\n",
      "Epoch 00441: saving model to training_1\\cp.ckpt\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7525 - val_loss: 18.6354\n",
      "\n",
      "Epoch 00442: saving model to training_1\\cp.ckpt\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7421 - val_loss: 18.6654\n",
      "\n",
      "Epoch 00443: saving model to training_1\\cp.ckpt\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.7316 - val_loss: 18.7029\n",
      "\n",
      "Epoch 00444: saving model to training_1\\cp.ckpt\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7450 - val_loss: 18.5659\n",
      "\n",
      "Epoch 00445: saving model to training_1\\cp.ckpt\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7735 - val_loss: 18.5864\n",
      "\n",
      "Epoch 00446: saving model to training_1\\cp.ckpt\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7632 - val_loss: 18.6070\n",
      "\n",
      "Epoch 00447: saving model to training_1\\cp.ckpt\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7528 - val_loss: 18.6340\n",
      "\n",
      "Epoch 00448: saving model to training_1\\cp.ckpt\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7424 - val_loss: 18.6637\n",
      "\n",
      "Epoch 00449: saving model to training_1\\cp.ckpt\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7319 - val_loss: 18.7011\n",
      "\n",
      "Epoch 00450: saving model to training_1\\cp.ckpt\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7430 - val_loss: 18.6290\n",
      "\n",
      "Epoch 00451: saving model to training_1\\cp.ckpt\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7442 - val_loss: 18.6573\n",
      "\n",
      "Epoch 00452: saving model to training_1\\cp.ckpt\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7337 - val_loss: 18.6942\n",
      "\n",
      "Epoch 00453: saving model to training_1\\cp.ckpt\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7390 - val_loss: 18.6240\n",
      "\n",
      "Epoch 00454: saving model to training_1\\cp.ckpt\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7459 - val_loss: 18.6523\n",
      "\n",
      "Epoch 00455: saving model to training_1\\cp.ckpt\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7354 - val_loss: 18.6873\n",
      "\n",
      "Epoch 00456: saving model to training_1\\cp.ckpt\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7349 - val_loss: 18.6190\n",
      "\n",
      "Epoch 00457: saving model to training_1\\cp.ckpt\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7476 - val_loss: 18.6472\n",
      "\n",
      "Epoch 00458: saving model to training_1\\cp.ckpt\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7372 - val_loss: 18.6805\n",
      "\n",
      "Epoch 00459: saving model to training_1\\cp.ckpt\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7309 - val_loss: 18.6140\n",
      "\n",
      "Epoch 00460: saving model to training_1\\cp.ckpt\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7494 - val_loss: 18.6422\n",
      "\n",
      "Epoch 00461: saving model to training_1\\cp.ckpt\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7390 - val_loss: 18.6741\n",
      "\n",
      "Epoch 00462: saving model to training_1\\cp.ckpt\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7284 - val_loss: 18.7134\n",
      "\n",
      "Epoch 00463: saving model to training_1\\cp.ckpt\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7582 - val_loss: 18.5707\n",
      "\n",
      "Epoch 00464: saving model to training_1\\cp.ckpt\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7704 - val_loss: 18.5913\n",
      "\n",
      "Epoch 00465: saving model to training_1\\cp.ckpt\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7601 - val_loss: 18.6126\n",
      "\n",
      "Epoch 00466: saving model to training_1\\cp.ckpt\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7497 - val_loss: 18.6409\n",
      "\n",
      "Epoch 00467: saving model to training_1\\cp.ckpt\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7393 - val_loss: 18.6724\n",
      "\n",
      "Epoch 00468: saving model to training_1\\cp.ckpt\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7287 - val_loss: 18.7112\n",
      "\n",
      "Epoch 00469: saving model to training_1\\cp.ckpt\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7558 - val_loss: 18.5697\n",
      "\n",
      "Epoch 00470: saving model to training_1\\cp.ckpt\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7707 - val_loss: 18.5902\n",
      "\n",
      "Epoch 00471: saving model to training_1\\cp.ckpt\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7604 - val_loss: 18.6113\n",
      "\n",
      "Epoch 00472: saving model to training_1\\cp.ckpt\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7500 - val_loss: 18.6395\n",
      "\n",
      "Epoch 00473: saving model to training_1\\cp.ckpt\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7396 - val_loss: 18.6707\n",
      "\n",
      "Epoch 00474: saving model to training_1\\cp.ckpt\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7291 - val_loss: 18.7090\n",
      "\n",
      "Epoch 00475: saving model to training_1\\cp.ckpt\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7533 - val_loss: 18.5687\n",
      "\n",
      "Epoch 00476: saving model to training_1\\cp.ckpt\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7710 - val_loss: 18.5892\n",
      "\n",
      "Epoch 00477: saving model to training_1\\cp.ckpt\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7606 - val_loss: 18.6099\n",
      "\n",
      "Epoch 00478: saving model to training_1\\cp.ckpt\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7503 - val_loss: 18.6382\n",
      "\n",
      "Epoch 00479: saving model to training_1\\cp.ckpt\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7399 - val_loss: 18.6691\n",
      "\n",
      "Epoch 00480: saving model to training_1\\cp.ckpt\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7294 - val_loss: 18.7068\n",
      "\n",
      "Epoch 00481: saving model to training_1\\cp.ckpt\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7509 - val_loss: 18.5677\n",
      "\n",
      "Epoch 00482: saving model to training_1\\cp.ckpt\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7712 - val_loss: 18.5882\n",
      "\n",
      "Epoch 00483: saving model to training_1\\cp.ckpt\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7609 - val_loss: 18.6088\n",
      "\n",
      "Epoch 00484: saving model to training_1\\cp.ckpt\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7506 - val_loss: 18.6368\n",
      "\n",
      "Epoch 00485: saving model to training_1\\cp.ckpt\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7402 - val_loss: 18.6674\n",
      "\n",
      "Epoch 00486: saving model to training_1\\cp.ckpt\n",
      "Epoch 487/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7297 - val_loss: 18.7050\n",
      "\n",
      "Epoch 00487: saving model to training_1\\cp.ckpt\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7485 - val_loss: 18.5668\n",
      "\n",
      "Epoch 00488: saving model to training_1\\cp.ckpt\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7715 - val_loss: 18.5872\n",
      "\n",
      "Epoch 00489: saving model to training_1\\cp.ckpt\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7612 - val_loss: 18.6078\n",
      "\n",
      "Epoch 00490: saving model to training_1\\cp.ckpt\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7509 - val_loss: 18.6355\n",
      "\n",
      "Epoch 00491: saving model to training_1\\cp.ckpt\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7404 - val_loss: 18.6657\n",
      "\n",
      "Epoch 00492: saving model to training_1\\cp.ckpt\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7300 - val_loss: 18.7032\n",
      "\n",
      "Epoch 00493: saving model to training_1\\cp.ckpt\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7462 - val_loss: 18.5658\n",
      "\n",
      "Epoch 00494: saving model to training_1\\cp.ckpt\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7718 - val_loss: 18.5862\n",
      "\n",
      "Epoch 00495: saving model to training_1\\cp.ckpt\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7615 - val_loss: 18.6068\n",
      "\n",
      "Epoch 00496: saving model to training_1\\cp.ckpt\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7512 - val_loss: 18.6341\n",
      "\n",
      "Epoch 00497: saving model to training_1\\cp.ckpt\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7407 - val_loss: 18.6641\n",
      "\n",
      "Epoch 00498: saving model to training_1\\cp.ckpt\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 19.7303 - val_loss: 18.7014\n",
      "\n",
      "Epoch 00499: saving model to training_1\\cp.ckpt\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 19.7438 - val_loss: 18.5648\n",
      "\n",
      "Epoch 00500: saving model to training_1\\cp.ckpt\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.7721 - val_loss: 18.5852\n",
      "\n",
      "Epoch 00501: saving model to training_1\\cp.ckpt\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7618 - val_loss: 18.6058\n",
      "\n",
      "Epoch 00502: saving model to training_1\\cp.ckpt\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 19.7514 - val_loss: 18.6328\n",
      "\n",
      "Epoch 00503: saving model to training_1\\cp.ckpt\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7410 - val_loss: 18.6624\n",
      "\n",
      "Epoch 00504: saving model to training_1\\cp.ckpt\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7306 - val_loss: 18.6995\n",
      "\n",
      "Epoch 00505: saving model to training_1\\cp.ckpt\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7419 - val_loss: 18.6278\n",
      "\n",
      "Epoch 00506: saving model to training_1\\cp.ckpt\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7428 - val_loss: 18.6561\n",
      "\n",
      "Epoch 00507: saving model to training_1\\cp.ckpt\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7323 - val_loss: 18.6927\n",
      "\n",
      "Epoch 00508: saving model to training_1\\cp.ckpt\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7378 - val_loss: 18.6228\n",
      "\n",
      "Epoch 00509: saving model to training_1\\cp.ckpt\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7445 - val_loss: 18.6511\n",
      "\n",
      "Epoch 00510: saving model to training_1\\cp.ckpt\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7341 - val_loss: 18.6859\n",
      "\n",
      "Epoch 00511: saving model to training_1\\cp.ckpt\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7338 - val_loss: 18.6179\n",
      "\n",
      "Epoch 00512: saving model to training_1\\cp.ckpt\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7463 - val_loss: 18.6461\n",
      "\n",
      "Epoch 00513: saving model to training_1\\cp.ckpt\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7358 - val_loss: 18.6793\n",
      "\n",
      "Epoch 00514: saving model to training_1\\cp.ckpt\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7298 - val_loss: 18.6129\n",
      "\n",
      "Epoch 00515: saving model to training_1\\cp.ckpt\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7480 - val_loss: 18.6411\n",
      "\n",
      "Epoch 00516: saving model to training_1\\cp.ckpt\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7376 - val_loss: 18.6730\n",
      "\n",
      "Epoch 00517: saving model to training_1\\cp.ckpt\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7271 - val_loss: 18.7120\n",
      "\n",
      "Epoch 00518: saving model to training_1\\cp.ckpt\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7571 - val_loss: 18.5697\n",
      "\n",
      "Epoch 00519: saving model to training_1\\cp.ckpt\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7689 - val_loss: 18.5902\n",
      "\n",
      "Epoch 00520: saving model to training_1\\cp.ckpt\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7586 - val_loss: 18.6116\n",
      "\n",
      "Epoch 00521: saving model to training_1\\cp.ckpt\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7483 - val_loss: 18.6398\n",
      "\n",
      "Epoch 00522: saving model to training_1\\cp.ckpt\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 19.7378 - val_loss: 18.6714\n",
      "\n",
      "Epoch 00523: saving model to training_1\\cp.ckpt\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7273 - val_loss: 18.7098\n",
      "\n",
      "Epoch 00524: saving model to training_1\\cp.ckpt\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 19.7548 - val_loss: 18.5688\n",
      "\n",
      "Epoch 00525: saving model to training_1\\cp.ckpt\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7692 - val_loss: 18.5892\n",
      "\n",
      "Epoch 00526: saving model to training_1\\cp.ckpt\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7589 - val_loss: 18.6103\n",
      "\n",
      "Epoch 00527: saving model to training_1\\cp.ckpt\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7486 - val_loss: 18.6385\n",
      "\n",
      "Epoch 00528: saving model to training_1\\cp.ckpt\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7381 - val_loss: 18.6697\n",
      "\n",
      "Epoch 00529: saving model to training_1\\cp.ckpt\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 19.7276 - val_loss: 18.7077\n",
      "\n",
      "Epoch 00530: saving model to training_1\\cp.ckpt\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7525 - val_loss: 18.5678\n",
      "\n",
      "Epoch 00531: saving model to training_1\\cp.ckpt\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7695 - val_loss: 18.5883\n",
      "\n",
      "Epoch 00532: saving model to training_1\\cp.ckpt\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 19.7592 - val_loss: 18.6090\n",
      "\n",
      "Epoch 00533: saving model to training_1\\cp.ckpt\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7488 - val_loss: 18.6372\n",
      "\n",
      "Epoch 00534: saving model to training_1\\cp.ckpt\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7384 - val_loss: 18.6681\n",
      "\n",
      "Epoch 00535: saving model to training_1\\cp.ckpt\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 19.7279 - val_loss: 18.7056\n",
      "\n",
      "Epoch 00536: saving model to training_1\\cp.ckpt\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 19.7501 - val_loss: 18.5668\n",
      "\n",
      "Epoch 00537: saving model to training_1\\cp.ckpt\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 19.7697 - val_loss: 18.5873\n",
      "\n",
      "Epoch 00538: saving model to training_1\\cp.ckpt\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7595 - val_loss: 18.6079\n",
      "\n",
      "Epoch 00539: saving model to training_1\\cp.ckpt\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7491 - val_loss: 18.6359\n",
      "\n",
      "Epoch 00540: saving model to training_1\\cp.ckpt\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step - loss: 19.7387 - val_loss: 18.6665\n",
      "\n",
      "Epoch 00541: saving model to training_1\\cp.ckpt\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7282 - val_loss: 18.7038\n",
      "\n",
      "Epoch 00542: saving model to training_1\\cp.ckpt\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7478 - val_loss: 18.5659\n",
      "\n",
      "Epoch 00543: saving model to training_1\\cp.ckpt\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7700 - val_loss: 18.5863\n",
      "\n",
      "Epoch 00544: saving model to training_1\\cp.ckpt\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7597 - val_loss: 18.6069\n",
      "\n",
      "Epoch 00545: saving model to training_1\\cp.ckpt\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7494 - val_loss: 18.6346\n",
      "\n",
      "Epoch 00546: saving model to training_1\\cp.ckpt\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7390 - val_loss: 18.6649\n",
      "\n",
      "Epoch 00547: saving model to training_1\\cp.ckpt\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7285 - val_loss: 18.7021\n",
      "\n",
      "Epoch 00548: saving model to training_1\\cp.ckpt\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7455 - val_loss: 18.5649\n",
      "\n",
      "Epoch 00549: saving model to training_1\\cp.ckpt\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7703 - val_loss: 18.5853\n",
      "\n",
      "Epoch 00550: saving model to training_1\\cp.ckpt\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7600 - val_loss: 18.6059\n",
      "\n",
      "Epoch 00551: saving model to training_1\\cp.ckpt\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7497 - val_loss: 18.6333\n",
      "\n",
      "Epoch 00552: saving model to training_1\\cp.ckpt\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7392 - val_loss: 18.6633\n",
      "\n",
      "Epoch 00553: saving model to training_1\\cp.ckpt\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7288 - val_loss: 18.7003\n",
      "\n",
      "Epoch 00554: saving model to training_1\\cp.ckpt\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7432 - val_loss: 18.5640\n",
      "\n",
      "Epoch 00555: saving model to training_1\\cp.ckpt\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7705 - val_loss: 18.5844\n",
      "\n",
      "Epoch 00556: saving model to training_1\\cp.ckpt\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7603 - val_loss: 18.6049\n",
      "\n",
      "Epoch 00557: saving model to training_1\\cp.ckpt\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7499 - val_loss: 18.6320\n",
      "\n",
      "Epoch 00558: saving model to training_1\\cp.ckpt\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7395 - val_loss: 18.6617\n",
      "\n",
      "Epoch 00559: saving model to training_1\\cp.ckpt\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7291 - val_loss: 18.6986\n",
      "\n",
      "Epoch 00560: saving model to training_1\\cp.ckpt\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7410 - val_loss: 18.6271\n",
      "\n",
      "Epoch 00561: saving model to training_1\\cp.ckpt\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7413 - val_loss: 18.6554\n",
      "\n",
      "Epoch 00562: saving model to training_1\\cp.ckpt\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 19.7308 - val_loss: 18.6917\n",
      "\n",
      "Epoch 00563: saving model to training_1\\cp.ckpt\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.7370 - val_loss: 18.6221\n",
      "\n",
      "Epoch 00564: saving model to training_1\\cp.ckpt\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 19.7430 - val_loss: 18.6504\n",
      "\n",
      "Epoch 00565: saving model to training_1\\cp.ckpt\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 19.7325 - val_loss: 18.6850\n",
      "\n",
      "Epoch 00566: saving model to training_1\\cp.ckpt\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7330 - val_loss: 18.6172\n",
      "\n",
      "Epoch 00567: saving model to training_1\\cp.ckpt\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7447 - val_loss: 18.6454\n",
      "\n",
      "Epoch 00568: saving model to training_1\\cp.ckpt\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.7343 - val_loss: 18.6786\n",
      "\n",
      "Epoch 00569: saving model to training_1\\cp.ckpt\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 19.7290 - val_loss: 18.6122\n",
      "\n",
      "Epoch 00570: saving model to training_1\\cp.ckpt\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.7464 - val_loss: 18.6404\n",
      "\n",
      "Epoch 00571: saving model to training_1\\cp.ckpt\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7360 - val_loss: 18.6724\n",
      "\n",
      "Epoch 00572: saving model to training_1\\cp.ckpt\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7255 - val_loss: 18.7112\n",
      "\n",
      "Epoch 00573: saving model to training_1\\cp.ckpt\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7568 - val_loss: 18.5690\n",
      "\n",
      "Epoch 00574: saving model to training_1\\cp.ckpt\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7673 - val_loss: 18.5894\n",
      "\n",
      "Epoch 00575: saving model to training_1\\cp.ckpt\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7571 - val_loss: 18.6110\n",
      "\n",
      "Epoch 00576: saving model to training_1\\cp.ckpt\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 19.7467 - val_loss: 18.6391\n",
      "\n",
      "Epoch 00577: saving model to training_1\\cp.ckpt\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7363 - val_loss: 18.6708\n",
      "\n",
      "Epoch 00578: saving model to training_1\\cp.ckpt\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7258 - val_loss: 18.7092\n",
      "\n",
      "Epoch 00579: saving model to training_1\\cp.ckpt\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7546 - val_loss: 18.5681\n",
      "\n",
      "Epoch 00580: saving model to training_1\\cp.ckpt\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7676 - val_loss: 18.5885\n",
      "\n",
      "Epoch 00581: saving model to training_1\\cp.ckpt\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7573 - val_loss: 18.6097\n",
      "\n",
      "Epoch 00582: saving model to training_1\\cp.ckpt\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7470 - val_loss: 18.6379\n",
      "\n",
      "Epoch 00583: saving model to training_1\\cp.ckpt\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 19.7366 - val_loss: 18.6692\n",
      "\n",
      "Epoch 00584: saving model to training_1\\cp.ckpt\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7261 - val_loss: 18.7071\n",
      "\n",
      "Epoch 00585: saving model to training_1\\cp.ckpt\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7523 - val_loss: 18.5671\n",
      "\n",
      "Epoch 00586: saving model to training_1\\cp.ckpt\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 19.7679 - val_loss: 18.5875\n",
      "\n",
      "Epoch 00587: saving model to training_1\\cp.ckpt\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7576 - val_loss: 18.6085\n",
      "\n",
      "Epoch 00588: saving model to training_1\\cp.ckpt\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7472 - val_loss: 18.6366\n",
      "\n",
      "Epoch 00589: saving model to training_1\\cp.ckpt\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7368 - val_loss: 18.6677\n",
      "\n",
      "Epoch 00590: saving model to training_1\\cp.ckpt\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7263 - val_loss: 18.7051\n",
      "\n",
      "Epoch 00591: saving model to training_1\\cp.ckpt\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7501 - val_loss: 18.5662\n",
      "\n",
      "Epoch 00592: saving model to training_1\\cp.ckpt\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 19.7681 - val_loss: 18.5866\n",
      "\n",
      "Epoch 00593: saving model to training_1\\cp.ckpt\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 19.7578 - val_loss: 18.6072\n",
      "\n",
      "Epoch 00594: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7475 - val_loss: 18.6354\n",
      "\n",
      "Epoch 00595: saving model to training_1\\cp.ckpt\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 19.7371 - val_loss: 18.6661\n",
      "\n",
      "Epoch 00596: saving model to training_1\\cp.ckpt\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 19.7266 - val_loss: 18.7032\n",
      "\n",
      "Epoch 00597: saving model to training_1\\cp.ckpt\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 19.7478 - val_loss: 18.5653\n",
      "\n",
      "Epoch 00598: saving model to training_1\\cp.ckpt\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 19.7684 - val_loss: 18.5857\n",
      "\n",
      "Epoch 00599: saving model to training_1\\cp.ckpt\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 19.7581 - val_loss: 18.6062\n",
      "\n",
      "Epoch 00600: saving model to training_1\\cp.ckpt\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 19.7477 - val_loss: 18.6341\n",
      "\n",
      "Epoch 00601: saving model to training_1\\cp.ckpt\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 19.7374 - val_loss: 18.6645\n",
      "\n",
      "Epoch 00602: saving model to training_1\\cp.ckpt\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 19.7269 - val_loss: 18.7015\n",
      "\n",
      "Epoch 00603: saving model to training_1\\cp.ckpt\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7456 - val_loss: 18.5643\n",
      "\n",
      "Epoch 00604: saving model to training_1\\cp.ckpt\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7686 - val_loss: 18.5847\n",
      "\n",
      "Epoch 00605: saving model to training_1\\cp.ckpt\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 19.7583 - val_loss: 18.6053\n",
      "\n",
      "Epoch 00606: saving model to training_1\\cp.ckpt\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 19.7480 - val_loss: 18.6329\n",
      "\n",
      "Epoch 00607: saving model to training_1\\cp.ckpt\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 19.7376 - val_loss: 18.6630\n",
      "\n",
      "Epoch 00608: saving model to training_1\\cp.ckpt\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 19.7271 - val_loss: 18.6998\n",
      "\n",
      "Epoch 00609: saving model to training_1\\cp.ckpt\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 19.7434 - val_loss: 18.5634\n",
      "\n",
      "Epoch 00610: saving model to training_1\\cp.ckpt\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 19.7688 - val_loss: 18.5838\n",
      "\n",
      "Epoch 00611: saving model to training_1\\cp.ckpt\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 19.7586 - val_loss: 18.6043\n",
      "\n",
      "Epoch 00612: saving model to training_1\\cp.ckpt\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 19.7483 - val_loss: 18.6316\n",
      "\n",
      "Epoch 00613: saving model to training_1\\cp.ckpt\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7379 - val_loss: 18.6615\n",
      "\n",
      "Epoch 00614: saving model to training_1\\cp.ckpt\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7274 - val_loss: 18.6981\n",
      "\n",
      "Epoch 00615: saving model to training_1\\cp.ckpt\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7412 - val_loss: 18.5625\n",
      "\n",
      "Epoch 00616: saving model to training_1\\cp.ckpt\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7691 - val_loss: 18.5829\n",
      "\n",
      "Epoch 00617: saving model to training_1\\cp.ckpt\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7588 - val_loss: 18.6034\n",
      "\n",
      "Epoch 00618: saving model to training_1\\cp.ckpt\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7485 - val_loss: 18.6304\n",
      "\n",
      "Epoch 00619: saving model to training_1\\cp.ckpt\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7381 - val_loss: 18.6599\n",
      "\n",
      "Epoch 00620: saving model to training_1\\cp.ckpt\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7277 - val_loss: 18.6964\n",
      "\n",
      "Epoch 00621: saving model to training_1\\cp.ckpt\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7394 - val_loss: 18.6255\n",
      "\n",
      "Epoch 00622: saving model to training_1\\cp.ckpt\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7398 - val_loss: 18.6537\n",
      "\n",
      "Epoch 00623: saving model to training_1\\cp.ckpt\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7294 - val_loss: 18.6897\n",
      "\n",
      "Epoch 00624: saving model to training_1\\cp.ckpt\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7354 - val_loss: 18.6205\n",
      "\n",
      "Epoch 00625: saving model to training_1\\cp.ckpt\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7416 - val_loss: 18.6487\n",
      "\n",
      "Epoch 00626: saving model to training_1\\cp.ckpt\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 19.7311 - val_loss: 18.6832\n",
      "\n",
      "Epoch 00627: saving model to training_1\\cp.ckpt\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 19.7315 - val_loss: 18.6156\n",
      "\n",
      "Epoch 00628: saving model to training_1\\cp.ckpt\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7433 - val_loss: 18.6438\n",
      "\n",
      "Epoch 00629: saving model to training_1\\cp.ckpt\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7329 - val_loss: 18.6769\n",
      "\n",
      "Epoch 00630: saving model to training_1\\cp.ckpt\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 19.7275 - val_loss: 18.6107\n",
      "\n",
      "Epoch 00631: saving model to training_1\\cp.ckpt\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7450 - val_loss: 18.6388\n",
      "\n",
      "Epoch 00632: saving model to training_1\\cp.ckpt\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7346 - val_loss: 18.6707\n",
      "\n",
      "Epoch 00633: saving model to training_1\\cp.ckpt\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7241 - val_loss: 18.7091\n",
      "\n",
      "Epoch 00634: saving model to training_1\\cp.ckpt\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7551 - val_loss: 18.5676\n",
      "\n",
      "Epoch 00635: saving model to training_1\\cp.ckpt\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7659 - val_loss: 18.5880\n",
      "\n",
      "Epoch 00636: saving model to training_1\\cp.ckpt\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7556 - val_loss: 18.6095\n",
      "\n",
      "Epoch 00637: saving model to training_1\\cp.ckpt\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7452 - val_loss: 18.6376\n",
      "\n",
      "Epoch 00638: saving model to training_1\\cp.ckpt\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7348 - val_loss: 18.6692\n",
      "\n",
      "Epoch 00639: saving model to training_1\\cp.ckpt\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7244 - val_loss: 18.7071\n",
      "\n",
      "Epoch 00640: saving model to training_1\\cp.ckpt\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7529 - val_loss: 18.5667\n",
      "\n",
      "Epoch 00641: saving model to training_1\\cp.ckpt\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7661 - val_loss: 18.5871\n",
      "\n",
      "Epoch 00642: saving model to training_1\\cp.ckpt\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7558 - val_loss: 18.6083\n",
      "\n",
      "Epoch 00643: saving model to training_1\\cp.ckpt\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7455 - val_loss: 18.6364\n",
      "\n",
      "Epoch 00644: saving model to training_1\\cp.ckpt\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7351 - val_loss: 18.6677\n",
      "\n",
      "Epoch 00645: saving model to training_1\\cp.ckpt\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7246 - val_loss: 18.7052\n",
      "\n",
      "Epoch 00646: saving model to training_1\\cp.ckpt\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7507 - val_loss: 18.5658\n",
      "\n",
      "Epoch 00647: saving model to training_1\\cp.ckpt\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7663 - val_loss: 18.5862\n",
      "\n",
      "Epoch 00648: saving model to training_1\\cp.ckpt\n",
      "Epoch 649/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7561 - val_loss: 18.6071\n",
      "\n",
      "Epoch 00649: saving model to training_1\\cp.ckpt\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7457 - val_loss: 18.6352\n",
      "\n",
      "Epoch 00650: saving model to training_1\\cp.ckpt\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 19.7353 - val_loss: 18.6662\n",
      "\n",
      "Epoch 00651: saving model to training_1\\cp.ckpt\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 19.7249 - val_loss: 18.7033\n",
      "\n",
      "Epoch 00652: saving model to training_1\\cp.ckpt\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 19.7486 - val_loss: 18.5649\n",
      "\n",
      "Epoch 00653: saving model to training_1\\cp.ckpt\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 19.7666 - val_loss: 18.5853\n",
      "\n",
      "Epoch 00654: saving model to training_1\\cp.ckpt\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 19.7563 - val_loss: 18.6059\n",
      "\n",
      "Epoch 00655: saving model to training_1\\cp.ckpt\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 19.7460 - val_loss: 18.6340\n",
      "\n",
      "Epoch 00656: saving model to training_1\\cp.ckpt\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 19.7356 - val_loss: 18.6647\n",
      "\n",
      "Epoch 00657: saving model to training_1\\cp.ckpt\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 19.7251 - val_loss: 18.7015\n",
      "\n",
      "Epoch 00658: saving model to training_1\\cp.ckpt\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7464 - val_loss: 18.5640\n",
      "\n",
      "Epoch 00659: saving model to training_1\\cp.ckpt\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7668 - val_loss: 18.5844\n",
      "\n",
      "Epoch 00660: saving model to training_1\\cp.ckpt\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 19.7565 - val_loss: 18.6049\n",
      "\n",
      "Epoch 00661: saving model to training_1\\cp.ckpt\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 19.7462 - val_loss: 18.6328\n",
      "\n",
      "Epoch 00662: saving model to training_1\\cp.ckpt\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7358 - val_loss: 18.6632\n",
      "\n",
      "Epoch 00663: saving model to training_1\\cp.ckpt\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7254 - val_loss: 18.6998\n",
      "\n",
      "Epoch 00664: saving model to training_1\\cp.ckpt\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7443 - val_loss: 18.5631\n",
      "\n",
      "Epoch 00665: saving model to training_1\\cp.ckpt\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7670 - val_loss: 18.5835\n",
      "\n",
      "Epoch 00666: saving model to training_1\\cp.ckpt\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7568 - val_loss: 18.6040\n",
      "\n",
      "Epoch 00667: saving model to training_1\\cp.ckpt\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7465 - val_loss: 18.6316\n",
      "\n",
      "Epoch 00668: saving model to training_1\\cp.ckpt\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7361 - val_loss: 18.6617\n",
      "\n",
      "Epoch 00669: saving model to training_1\\cp.ckpt\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7256 - val_loss: 18.6982\n",
      "\n",
      "Epoch 00670: saving model to training_1\\cp.ckpt\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7422 - val_loss: 18.5622\n",
      "\n",
      "Epoch 00671: saving model to training_1\\cp.ckpt\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7673 - val_loss: 18.5826\n",
      "\n",
      "Epoch 00672: saving model to training_1\\cp.ckpt\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7570 - val_loss: 18.6031\n",
      "\n",
      "Epoch 00673: saving model to training_1\\cp.ckpt\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7467 - val_loss: 18.6304\n",
      "\n",
      "Epoch 00674: saving model to training_1\\cp.ckpt\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7363 - val_loss: 18.6602\n",
      "\n",
      "Epoch 00675: saving model to training_1\\cp.ckpt\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7259 - val_loss: 18.6966\n",
      "\n",
      "Epoch 00676: saving model to training_1\\cp.ckpt\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7401 - val_loss: 18.5614\n",
      "\n",
      "Epoch 00677: saving model to training_1\\cp.ckpt\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7675 - val_loss: 18.5817\n",
      "\n",
      "Epoch 00678: saving model to training_1\\cp.ckpt\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7572 - val_loss: 18.6022\n",
      "\n",
      "Epoch 00679: saving model to training_1\\cp.ckpt\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7469 - val_loss: 18.6292\n",
      "\n",
      "Epoch 00680: saving model to training_1\\cp.ckpt\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7366 - val_loss: 18.6588\n",
      "\n",
      "Epoch 00681: saving model to training_1\\cp.ckpt\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7261 - val_loss: 18.6949\n",
      "\n",
      "Epoch 00682: saving model to training_1\\cp.ckpt\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7383 - val_loss: 18.6243\n",
      "\n",
      "Epoch 00683: saving model to training_1\\cp.ckpt\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7383 - val_loss: 18.6526\n",
      "\n",
      "Epoch 00684: saving model to training_1\\cp.ckpt\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7278 - val_loss: 18.6882\n",
      "\n",
      "Epoch 00685: saving model to training_1\\cp.ckpt\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7343 - val_loss: 18.6194\n",
      "\n",
      "Epoch 00686: saving model to training_1\\cp.ckpt\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7400 - val_loss: 18.6476\n",
      "\n",
      "Epoch 00687: saving model to training_1\\cp.ckpt\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7295 - val_loss: 18.6820\n",
      "\n",
      "Epoch 00688: saving model to training_1\\cp.ckpt\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7303 - val_loss: 18.6146\n",
      "\n",
      "Epoch 00689: saving model to training_1\\cp.ckpt\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7417 - val_loss: 18.6427\n",
      "\n",
      "Epoch 00690: saving model to training_1\\cp.ckpt\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7313 - val_loss: 18.6758\n",
      "\n",
      "Epoch 00691: saving model to training_1\\cp.ckpt\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7264 - val_loss: 18.6097\n",
      "\n",
      "Epoch 00692: saving model to training_1\\cp.ckpt\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7434 - val_loss: 18.6378\n",
      "\n",
      "Epoch 00693: saving model to training_1\\cp.ckpt\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7330 - val_loss: 18.6696\n",
      "\n",
      "Epoch 00694: saving model to training_1\\cp.ckpt\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7225 - val_loss: 18.7078\n",
      "\n",
      "Epoch 00695: saving model to training_1\\cp.ckpt\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7542 - val_loss: 18.5666\n",
      "\n",
      "Epoch 00696: saving model to training_1\\cp.ckpt\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7642 - val_loss: 18.5870\n",
      "\n",
      "Epoch 00697: saving model to training_1\\cp.ckpt\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7539 - val_loss: 18.6085\n",
      "\n",
      "Epoch 00698: saving model to training_1\\cp.ckpt\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7436 - val_loss: 18.6366\n",
      "\n",
      "Epoch 00699: saving model to training_1\\cp.ckpt\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7332 - val_loss: 18.6682\n",
      "\n",
      "Epoch 00700: saving model to training_1\\cp.ckpt\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7228 - val_loss: 18.7059\n",
      "\n",
      "Epoch 00701: saving model to training_1\\cp.ckpt\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7521 - val_loss: 18.5657\n",
      "\n",
      "Epoch 00702: saving model to training_1\\cp.ckpt\n",
      "Epoch 703/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7644 - val_loss: 18.5861\n",
      "\n",
      "Epoch 00703: saving model to training_1\\cp.ckpt\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7542 - val_loss: 18.6074\n",
      "\n",
      "Epoch 00704: saving model to training_1\\cp.ckpt\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7438 - val_loss: 18.6354\n",
      "\n",
      "Epoch 00705: saving model to training_1\\cp.ckpt\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7334 - val_loss: 18.6667\n",
      "\n",
      "Epoch 00706: saving model to training_1\\cp.ckpt\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7230 - val_loss: 18.7040\n",
      "\n",
      "Epoch 00707: saving model to training_1\\cp.ckpt\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7500 - val_loss: 18.5648\n",
      "\n",
      "Epoch 00708: saving model to training_1\\cp.ckpt\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7646 - val_loss: 18.5852\n",
      "\n",
      "Epoch 00709: saving model to training_1\\cp.ckpt\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7544 - val_loss: 18.6062\n",
      "\n",
      "Epoch 00710: saving model to training_1\\cp.ckpt\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 19.7441 - val_loss: 18.6343\n",
      "\n",
      "Epoch 00711: saving model to training_1\\cp.ckpt\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7337 - val_loss: 18.6653\n",
      "\n",
      "Epoch 00712: saving model to training_1\\cp.ckpt\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7232 - val_loss: 18.7022\n",
      "\n",
      "Epoch 00713: saving model to training_1\\cp.ckpt\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7480 - val_loss: 18.5640\n",
      "\n",
      "Epoch 00714: saving model to training_1\\cp.ckpt\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7649 - val_loss: 18.5843\n",
      "\n",
      "Epoch 00715: saving model to training_1\\cp.ckpt\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7546 - val_loss: 18.6051\n",
      "\n",
      "Epoch 00716: saving model to training_1\\cp.ckpt\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7443 - val_loss: 18.6331\n",
      "\n",
      "Epoch 00717: saving model to training_1\\cp.ckpt\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7339 - val_loss: 18.6639\n",
      "\n",
      "Epoch 00718: saving model to training_1\\cp.ckpt\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7235 - val_loss: 18.7004\n",
      "\n",
      "Epoch 00719: saving model to training_1\\cp.ckpt\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7459 - val_loss: 18.5631\n",
      "\n",
      "Epoch 00720: saving model to training_1\\cp.ckpt\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7651 - val_loss: 18.5835\n",
      "\n",
      "Epoch 00721: saving model to training_1\\cp.ckpt\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7548 - val_loss: 18.6040\n",
      "\n",
      "Epoch 00722: saving model to training_1\\cp.ckpt\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7445 - val_loss: 18.6320\n",
      "\n",
      "Epoch 00723: saving model to training_1\\cp.ckpt\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7341 - val_loss: 18.6624\n",
      "\n",
      "Epoch 00724: saving model to training_1\\cp.ckpt\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7237 - val_loss: 18.6988\n",
      "\n",
      "Epoch 00725: saving model to training_1\\cp.ckpt\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7439 - val_loss: 18.5623\n",
      "\n",
      "Epoch 00726: saving model to training_1\\cp.ckpt\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7653 - val_loss: 18.5826\n",
      "\n",
      "Epoch 00727: saving model to training_1\\cp.ckpt\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7550 - val_loss: 18.6031\n",
      "\n",
      "Epoch 00728: saving model to training_1\\cp.ckpt\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7447 - val_loss: 18.6308\n",
      "\n",
      "Epoch 00729: saving model to training_1\\cp.ckpt\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7344 - val_loss: 18.6610\n",
      "\n",
      "Epoch 00730: saving model to training_1\\cp.ckpt\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7239 - val_loss: 18.6972\n",
      "\n",
      "Epoch 00731: saving model to training_1\\cp.ckpt\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7418 - val_loss: 18.5614\n",
      "\n",
      "Epoch 00732: saving model to training_1\\cp.ckpt\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7655 - val_loss: 18.5818\n",
      "\n",
      "Epoch 00733: saving model to training_1\\cp.ckpt\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7553 - val_loss: 18.6022\n",
      "\n",
      "Epoch 00734: saving model to training_1\\cp.ckpt\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7450 - val_loss: 18.6297\n",
      "\n",
      "Epoch 00735: saving model to training_1\\cp.ckpt\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7346 - val_loss: 18.6596\n",
      "\n",
      "Epoch 00736: saving model to training_1\\cp.ckpt\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7241 - val_loss: 18.6957\n",
      "\n",
      "Epoch 00737: saving model to training_1\\cp.ckpt\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7398 - val_loss: 18.5606\n",
      "\n",
      "Epoch 00738: saving model to training_1\\cp.ckpt\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7657 - val_loss: 18.5809\n",
      "\n",
      "Epoch 00739: saving model to training_1\\cp.ckpt\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7555 - val_loss: 18.6014\n",
      "\n",
      "Epoch 00740: saving model to training_1\\cp.ckpt\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7452 - val_loss: 18.6285\n",
      "\n",
      "Epoch 00741: saving model to training_1\\cp.ckpt\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7348 - val_loss: 18.6582\n",
      "\n",
      "Epoch 00742: saving model to training_1\\cp.ckpt\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 19.7244 - val_loss: 18.6941\n",
      "\n",
      "Epoch 00743: saving model to training_1\\cp.ckpt\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7378 - val_loss: 18.5597\n",
      "\n",
      "Epoch 00744: saving model to training_1\\cp.ckpt\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7659 - val_loss: 18.5800\n",
      "\n",
      "Epoch 00745: saving model to training_1\\cp.ckpt\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 19.7557 - val_loss: 18.6005\n",
      "\n",
      "Epoch 00746: saving model to training_1\\cp.ckpt\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7454 - val_loss: 18.6274\n",
      "\n",
      "Epoch 00747: saving model to training_1\\cp.ckpt\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 19.7350 - val_loss: 18.6568\n",
      "\n",
      "Epoch 00748: saving model to training_1\\cp.ckpt\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 19.7246 - val_loss: 18.6926\n",
      "\n",
      "Epoch 00749: saving model to training_1\\cp.ckpt\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7365 - val_loss: 18.6225\n",
      "\n",
      "Epoch 00750: saving model to training_1\\cp.ckpt\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7367 - val_loss: 18.6507\n",
      "\n",
      "Epoch 00751: saving model to training_1\\cp.ckpt\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 19.7263 - val_loss: 18.6862\n",
      "\n",
      "Epoch 00752: saving model to training_1\\cp.ckpt\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7326 - val_loss: 18.6177\n",
      "\n",
      "Epoch 00753: saving model to training_1\\cp.ckpt\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7384 - val_loss: 18.6458\n",
      "\n",
      "Epoch 00754: saving model to training_1\\cp.ckpt\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7280 - val_loss: 18.6801\n",
      "\n",
      "Epoch 00755: saving model to training_1\\cp.ckpt\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 19.7287 - val_loss: 18.6128\n",
      "\n",
      "Epoch 00756: saving model to training_1\\cp.ckpt\n",
      "Epoch 757/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7401 - val_loss: 18.6409\n",
      "\n",
      "Epoch 00757: saving model to training_1\\cp.ckpt\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7297 - val_loss: 18.6739\n",
      "\n",
      "Epoch 00758: saving model to training_1\\cp.ckpt\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 19.7247 - val_loss: 18.6080\n",
      "\n",
      "Epoch 00759: saving model to training_1\\cp.ckpt\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7418 - val_loss: 18.6360\n",
      "\n",
      "Epoch 00760: saving model to training_1\\cp.ckpt\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7314 - val_loss: 18.6678\n",
      "\n",
      "Epoch 00761: saving model to training_1\\cp.ckpt\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7210 - val_loss: 18.7055\n",
      "\n",
      "Epoch 00762: saving model to training_1\\cp.ckpt\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7522 - val_loss: 18.5650\n",
      "\n",
      "Epoch 00763: saving model to training_1\\cp.ckpt\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7626 - val_loss: 18.5854\n",
      "\n",
      "Epoch 00764: saving model to training_1\\cp.ckpt\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7523 - val_loss: 18.6069\n",
      "\n",
      "Epoch 00765: saving model to training_1\\cp.ckpt\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7420 - val_loss: 18.6349\n",
      "\n",
      "Epoch 00766: saving model to training_1\\cp.ckpt\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7316 - val_loss: 18.6664\n",
      "\n",
      "Epoch 00767: saving model to training_1\\cp.ckpt\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7212 - val_loss: 18.7037\n",
      "\n",
      "Epoch 00768: saving model to training_1\\cp.ckpt\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7502 - val_loss: 18.5642\n",
      "\n",
      "Epoch 00769: saving model to training_1\\cp.ckpt\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7628 - val_loss: 18.5846\n",
      "\n",
      "Epoch 00770: saving model to training_1\\cp.ckpt\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 19.7525 - val_loss: 18.6058\n",
      "\n",
      "Epoch 00771: saving model to training_1\\cp.ckpt\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 19.7422 - val_loss: 18.6338\n",
      "\n",
      "Epoch 00772: saving model to training_1\\cp.ckpt\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 19.7318 - val_loss: 18.6650\n",
      "\n",
      "Epoch 00773: saving model to training_1\\cp.ckpt\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7214 - val_loss: 18.7019\n",
      "\n",
      "Epoch 00774: saving model to training_1\\cp.ckpt\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7482 - val_loss: 18.5634\n",
      "\n",
      "Epoch 00775: saving model to training_1\\cp.ckpt\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7630 - val_loss: 18.5837\n",
      "\n",
      "Epoch 00776: saving model to training_1\\cp.ckpt\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7527 - val_loss: 18.6047\n",
      "\n",
      "Epoch 00777: saving model to training_1\\cp.ckpt\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7424 - val_loss: 18.6327\n",
      "\n",
      "Epoch 00778: saving model to training_1\\cp.ckpt\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.7321 - val_loss: 18.6636\n",
      "\n",
      "Epoch 00779: saving model to training_1\\cp.ckpt\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7216 - val_loss: 18.7001\n",
      "\n",
      "Epoch 00780: saving model to training_1\\cp.ckpt\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7463 - val_loss: 18.5626\n",
      "\n",
      "Epoch 00781: saving model to training_1\\cp.ckpt\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7632 - val_loss: 18.5829\n",
      "\n",
      "Epoch 00782: saving model to training_1\\cp.ckpt\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7529 - val_loss: 18.6036\n",
      "\n",
      "Epoch 00783: saving model to training_1\\cp.ckpt\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7426 - val_loss: 18.6316\n",
      "\n",
      "Epoch 00784: saving model to training_1\\cp.ckpt\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.73 - 0s 67ms/step - loss: 19.7323 - val_loss: 18.6623\n",
      "\n",
      "Epoch 00785: saving model to training_1\\cp.ckpt\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7218 - val_loss: 18.6984\n",
      "\n",
      "Epoch 00786: saving model to training_1\\cp.ckpt\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7443 - val_loss: 18.5617\n",
      "\n",
      "Epoch 00787: saving model to training_1\\cp.ckpt\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 19.7634 - val_loss: 18.5821\n",
      "\n",
      "Epoch 00788: saving model to training_1\\cp.ckpt\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7531 - val_loss: 18.6025\n",
      "\n",
      "Epoch 00789: saving model to training_1\\cp.ckpt\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7428 - val_loss: 18.6305\n",
      "\n",
      "Epoch 00790: saving model to training_1\\cp.ckpt\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 19.7325 - val_loss: 18.6609\n",
      "\n",
      "Epoch 00791: saving model to training_1\\cp.ckpt\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7220 - val_loss: 18.6969\n",
      "\n",
      "Epoch 00792: saving model to training_1\\cp.ckpt\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 19.7424 - val_loss: 18.5609\n",
      "\n",
      "Epoch 00793: saving model to training_1\\cp.ckpt\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7636 - val_loss: 18.5812\n",
      "\n",
      "Epoch 00794: saving model to training_1\\cp.ckpt\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 19.7533 - val_loss: 18.6017\n",
      "\n",
      "Epoch 00795: saving model to training_1\\cp.ckpt\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 19.7430 - val_loss: 18.6294\n",
      "\n",
      "Epoch 00796: saving model to training_1\\cp.ckpt\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 19.7327 - val_loss: 18.6596\n",
      "\n",
      "Epoch 00797: saving model to training_1\\cp.ckpt\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 19.7222 - val_loss: 18.6954\n",
      "\n",
      "Epoch 00798: saving model to training_1\\cp.ckpt\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 19.7405 - val_loss: 18.5601\n",
      "\n",
      "Epoch 00799: saving model to training_1\\cp.ckpt\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7638 - val_loss: 18.5804\n",
      "\n",
      "Epoch 00800: saving model to training_1\\cp.ckpt\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 19.7535 - val_loss: 18.6008\n",
      "\n",
      "Epoch 00801: saving model to training_1\\cp.ckpt\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 19.7432 - val_loss: 18.6283\n",
      "\n",
      "Epoch 00802: saving model to training_1\\cp.ckpt\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 19.7329 - val_loss: 18.6582\n",
      "\n",
      "Epoch 00803: saving model to training_1\\cp.ckpt\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 19.7225 - val_loss: 18.6939\n",
      "\n",
      "Epoch 00804: saving model to training_1\\cp.ckpt\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 19.7386 - val_loss: 18.5593\n",
      "\n",
      "Epoch 00805: saving model to training_1\\cp.ckpt\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7639 - val_loss: 18.5796\n",
      "\n",
      "Epoch 00806: saving model to training_1\\cp.ckpt\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7537 - val_loss: 18.6000\n",
      "\n",
      "Epoch 00807: saving model to training_1\\cp.ckpt\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7434 - val_loss: 18.6272\n",
      "\n",
      "Epoch 00808: saving model to training_1\\cp.ckpt\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7331 - val_loss: 18.6569\n",
      "\n",
      "Epoch 00809: saving model to training_1\\cp.ckpt\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7227 - val_loss: 18.6925\n",
      "\n",
      "Epoch 00810: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 19.7367 - val_loss: 18.5585\n",
      "\n",
      "Epoch 00811: saving model to training_1\\cp.ckpt\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 19.7641 - val_loss: 18.5788\n",
      "\n",
      "Epoch 00812: saving model to training_1\\cp.ckpt\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 19.7539 - val_loss: 18.5992\n",
      "\n",
      "Epoch 00813: saving model to training_1\\cp.ckpt\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7436 - val_loss: 18.6261\n",
      "\n",
      "Epoch 00814: saving model to training_1\\cp.ckpt\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7333 - val_loss: 18.6555\n",
      "\n",
      "Epoch 00815: saving model to training_1\\cp.ckpt\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 19.7229 - val_loss: 18.6911\n",
      "\n",
      "Epoch 00816: saving model to training_1\\cp.ckpt\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7352 - val_loss: 18.6213\n",
      "\n",
      "Epoch 00817: saving model to training_1\\cp.ckpt\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 19.7350 - val_loss: 18.6495\n",
      "\n",
      "Epoch 00818: saving model to training_1\\cp.ckpt\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 19.7246 - val_loss: 18.6850\n",
      "\n",
      "Epoch 00819: saving model to training_1\\cp.ckpt\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7313 - val_loss: 18.6165\n",
      "\n",
      "Epoch 00820: saving model to training_1\\cp.ckpt\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7366 - val_loss: 18.6446\n",
      "\n",
      "Epoch 00821: saving model to training_1\\cp.ckpt\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7262 - val_loss: 18.6789\n",
      "\n",
      "Epoch 00822: saving model to training_1\\cp.ckpt\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7274 - val_loss: 18.6117\n",
      "\n",
      "Epoch 00823: saving model to training_1\\cp.ckpt\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7383 - val_loss: 18.6397\n",
      "\n",
      "Epoch 00824: saving model to training_1\\cp.ckpt\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 19.7279 - val_loss: 18.6728\n",
      "\n",
      "Epoch 00825: saving model to training_1\\cp.ckpt\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 19.7235 - val_loss: 18.6069\n",
      "\n",
      "Epoch 00826: saving model to training_1\\cp.ckpt\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7400 - val_loss: 18.6349\n",
      "\n",
      "Epoch 00827: saving model to training_1\\cp.ckpt\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 19.7296 - val_loss: 18.6667\n",
      "\n",
      "Epoch 00828: saving model to training_1\\cp.ckpt\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 19.7197 - val_loss: 18.6021\n",
      "\n",
      "Epoch 00829: saving model to training_1\\cp.ckpt\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 19.7417 - val_loss: 18.6300\n",
      "\n",
      "Epoch 00830: saving model to training_1\\cp.ckpt\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 19.7313 - val_loss: 18.6606\n",
      "\n",
      "Epoch 00831: saving model to training_1\\cp.ckpt\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 19.7209 - val_loss: 18.6964\n",
      "\n",
      "Epoch 00832: saving model to training_1\\cp.ckpt\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7424 - val_loss: 18.5604\n",
      "\n",
      "Epoch 00833: saving model to training_1\\cp.ckpt\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 19.7624 - val_loss: 18.5807\n",
      "\n",
      "Epoch 00834: saving model to training_1\\cp.ckpt\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7522 - val_loss: 18.6011\n",
      "\n",
      "Epoch 00835: saving model to training_1\\cp.ckpt\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7419 - val_loss: 18.6290\n",
      "\n",
      "Epoch 00836: saving model to training_1\\cp.ckpt\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7315 - val_loss: 18.6593\n",
      "\n",
      "Epoch 00837: saving model to training_1\\cp.ckpt\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 19.7211 - val_loss: 18.6950\n",
      "\n",
      "Epoch 00838: saving model to training_1\\cp.ckpt\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 19.7405 - val_loss: 18.5596\n",
      "\n",
      "Epoch 00839: saving model to training_1\\cp.ckpt\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 19.7626 - val_loss: 18.5799\n",
      "\n",
      "Epoch 00840: saving model to training_1\\cp.ckpt\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7523 - val_loss: 18.6003\n",
      "\n",
      "Epoch 00841: saving model to training_1\\cp.ckpt\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 19.7421 - val_loss: 18.6279\n",
      "\n",
      "Epoch 00842: saving model to training_1\\cp.ckpt\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 19.7317 - val_loss: 18.6579\n",
      "\n",
      "Epoch 00843: saving model to training_1\\cp.ckpt\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7213 - val_loss: 18.6935\n",
      "\n",
      "Epoch 00844: saving model to training_1\\cp.ckpt\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7386 - val_loss: 18.5588\n",
      "\n",
      "Epoch 00845: saving model to training_1\\cp.ckpt\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7627 - val_loss: 18.5791\n",
      "\n",
      "Epoch 00846: saving model to training_1\\cp.ckpt\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7525 - val_loss: 18.5995\n",
      "\n",
      "Epoch 00847: saving model to training_1\\cp.ckpt\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7422 - val_loss: 18.6269\n",
      "\n",
      "Epoch 00848: saving model to training_1\\cp.ckpt\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7319 - val_loss: 18.6566\n",
      "\n",
      "Epoch 00849: saving model to training_1\\cp.ckpt\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7215 - val_loss: 18.6922\n",
      "\n",
      "Epoch 00850: saving model to training_1\\cp.ckpt\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7368 - val_loss: 18.5580\n",
      "\n",
      "Epoch 00851: saving model to training_1\\cp.ckpt\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7629 - val_loss: 18.5783\n",
      "\n",
      "Epoch 00852: saving model to training_1\\cp.ckpt\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 19.7527 - val_loss: 18.5987\n",
      "\n",
      "Epoch 00853: saving model to training_1\\cp.ckpt\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 19.7424 - val_loss: 18.6258\n",
      "\n",
      "Epoch 00854: saving model to training_1\\cp.ckpt\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 19.7321 - val_loss: 18.6553\n",
      "\n",
      "Epoch 00855: saving model to training_1\\cp.ckpt\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 19.7217 - val_loss: 18.6909\n",
      "\n",
      "Epoch 00856: saving model to training_1\\cp.ckpt\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 19.7349 - val_loss: 18.5573\n",
      "\n",
      "Epoch 00857: saving model to training_1\\cp.ckpt\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7631 - val_loss: 18.5775\n",
      "\n",
      "Epoch 00858: saving model to training_1\\cp.ckpt\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7529 - val_loss: 18.5979\n",
      "\n",
      "Epoch 00859: saving model to training_1\\cp.ckpt\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 19.7426 - val_loss: 18.6248\n",
      "\n",
      "Epoch 00860: saving model to training_1\\cp.ckpt\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.7323 - val_loss: 18.6541\n",
      "\n",
      "Epoch 00861: saving model to training_1\\cp.ckpt\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7219 - val_loss: 18.6896\n",
      "\n",
      "Epoch 00862: saving model to training_1\\cp.ckpt\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7340 - val_loss: 18.6200\n",
      "\n",
      "Epoch 00863: saving model to training_1\\cp.ckpt\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7339 - val_loss: 18.6480\n",
      "\n",
      "Epoch 00864: saving model to training_1\\cp.ckpt\n",
      "Epoch 865/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7235 - val_loss: 18.6835\n",
      "\n",
      "Epoch 00865: saving model to training_1\\cp.ckpt\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7301 - val_loss: 18.6152\n",
      "\n",
      "Epoch 00866: saving model to training_1\\cp.ckpt\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7356 - val_loss: 18.6432\n",
      "\n",
      "Epoch 00867: saving model to training_1\\cp.ckpt\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7252 - val_loss: 18.6774\n",
      "\n",
      "Epoch 00868: saving model to training_1\\cp.ckpt\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7262 - val_loss: 18.6104\n",
      "\n",
      "Epoch 00869: saving model to training_1\\cp.ckpt\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 19.7373 - val_loss: 18.6384\n",
      "\n",
      "Epoch 00870: saving model to training_1\\cp.ckpt\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7269 - val_loss: 18.6713\n",
      "\n",
      "Epoch 00871: saving model to training_1\\cp.ckpt\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 19.7223 - val_loss: 18.6056\n",
      "\n",
      "Epoch 00872: saving model to training_1\\cp.ckpt\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7390 - val_loss: 18.6336\n",
      "\n",
      "Epoch 00873: saving model to training_1\\cp.ckpt\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7286 - val_loss: 18.6653\n",
      "\n",
      "Epoch 00874: saving model to training_1\\cp.ckpt\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7185 - val_loss: 18.6008\n",
      "\n",
      "Epoch 00875: saving model to training_1\\cp.ckpt\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 19.7406 - val_loss: 18.6288\n",
      "\n",
      "Epoch 00876: saving model to training_1\\cp.ckpt\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 19.7303 - val_loss: 18.6592\n",
      "\n",
      "Epoch 00877: saving model to training_1\\cp.ckpt\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 19.7198 - val_loss: 18.6948\n",
      "\n",
      "Epoch 00878: saving model to training_1\\cp.ckpt\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7409 - val_loss: 18.5593\n",
      "\n",
      "Epoch 00879: saving model to training_1\\cp.ckpt\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7613 - val_loss: 18.5796\n",
      "\n",
      "Epoch 00880: saving model to training_1\\cp.ckpt\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7511 - val_loss: 18.6000\n",
      "\n",
      "Epoch 00881: saving model to training_1\\cp.ckpt\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7408 - val_loss: 18.6277\n",
      "\n",
      "Epoch 00882: saving model to training_1\\cp.ckpt\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7304 - val_loss: 18.6579\n",
      "\n",
      "Epoch 00883: saving model to training_1\\cp.ckpt\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7200 - val_loss: 18.6935\n",
      "\n",
      "Epoch 00884: saving model to training_1\\cp.ckpt\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7391 - val_loss: 18.5585\n",
      "\n",
      "Epoch 00885: saving model to training_1\\cp.ckpt\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7615 - val_loss: 18.5788\n",
      "\n",
      "Epoch 00886: saving model to training_1\\cp.ckpt\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7513 - val_loss: 18.5992\n",
      "\n",
      "Epoch 00887: saving model to training_1\\cp.ckpt\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7410 - val_loss: 18.6267\n",
      "\n",
      "Epoch 00888: saving model to training_1\\cp.ckpt\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7306 - val_loss: 18.6567\n",
      "\n",
      "Epoch 00889: saving model to training_1\\cp.ckpt\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7202 - val_loss: 18.6922\n",
      "\n",
      "Epoch 00890: saving model to training_1\\cp.ckpt\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7373 - val_loss: 18.5578\n",
      "\n",
      "Epoch 00891: saving model to training_1\\cp.ckpt\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7616 - val_loss: 18.5780\n",
      "\n",
      "Epoch 00892: saving model to training_1\\cp.ckpt\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7514 - val_loss: 18.5984\n",
      "\n",
      "Epoch 00893: saving model to training_1\\cp.ckpt\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7411 - val_loss: 18.6257\n",
      "\n",
      "Epoch 00894: saving model to training_1\\cp.ckpt\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7308 - val_loss: 18.6554\n",
      "\n",
      "Epoch 00895: saving model to training_1\\cp.ckpt\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7204 - val_loss: 18.6909\n",
      "\n",
      "Epoch 00896: saving model to training_1\\cp.ckpt\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7355 - val_loss: 18.5570\n",
      "\n",
      "Epoch 00897: saving model to training_1\\cp.ckpt\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7618 - val_loss: 18.5772\n",
      "\n",
      "Epoch 00898: saving model to training_1\\cp.ckpt\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7516 - val_loss: 18.5976\n",
      "\n",
      "Epoch 00899: saving model to training_1\\cp.ckpt\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.7413 - val_loss: 18.6247\n",
      "\n",
      "Epoch 00900: saving model to training_1\\cp.ckpt\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7310 - val_loss: 18.6542\n",
      "\n",
      "Epoch 00901: saving model to training_1\\cp.ckpt\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7206 - val_loss: 18.6897\n",
      "\n",
      "Epoch 00902: saving model to training_1\\cp.ckpt\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7338 - val_loss: 18.6199\n",
      "\n",
      "Epoch 00903: saving model to training_1\\cp.ckpt\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7326 - val_loss: 18.6481\n",
      "\n",
      "Epoch 00904: saving model to training_1\\cp.ckpt\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7222 - val_loss: 18.6836\n",
      "\n",
      "Epoch 00905: saving model to training_1\\cp.ckpt\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7299 - val_loss: 18.6151\n",
      "\n",
      "Epoch 00906: saving model to training_1\\cp.ckpt\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7343 - val_loss: 18.6431\n",
      "\n",
      "Epoch 00907: saving model to training_1\\cp.ckpt\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7239 - val_loss: 18.6775\n",
      "\n",
      "Epoch 00908: saving model to training_1\\cp.ckpt\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7260 - val_loss: 18.6104\n",
      "\n",
      "Epoch 00909: saving model to training_1\\cp.ckpt\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7360 - val_loss: 18.6383\n",
      "\n",
      "Epoch 00910: saving model to training_1\\cp.ckpt\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7256 - val_loss: 18.6715\n",
      "\n",
      "Epoch 00911: saving model to training_1\\cp.ckpt\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7222 - val_loss: 18.6056\n",
      "\n",
      "Epoch 00912: saving model to training_1\\cp.ckpt\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7376 - val_loss: 18.6335\n",
      "\n",
      "Epoch 00913: saving model to training_1\\cp.ckpt\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7273 - val_loss: 18.6654\n",
      "\n",
      "Epoch 00914: saving model to training_1\\cp.ckpt\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7183 - val_loss: 18.6008\n",
      "\n",
      "Epoch 00915: saving model to training_1\\cp.ckpt\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7393 - val_loss: 18.6288\n",
      "\n",
      "Epoch 00916: saving model to training_1\\cp.ckpt\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7290 - val_loss: 18.6594\n",
      "\n",
      "Epoch 00917: saving model to training_1\\cp.ckpt\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7185 - val_loss: 18.6950\n",
      "\n",
      "Epoch 00918: saving model to training_1\\cp.ckpt\n",
      "Epoch 919/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7417 - val_loss: 18.5591\n",
      "\n",
      "Epoch 00919: saving model to training_1\\cp.ckpt\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7600 - val_loss: 18.5793\n",
      "\n",
      "Epoch 00920: saving model to training_1\\cp.ckpt\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7498 - val_loss: 18.5999\n",
      "\n",
      "Epoch 00921: saving model to training_1\\cp.ckpt\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7395 - val_loss: 18.6278\n",
      "\n",
      "Epoch 00922: saving model to training_1\\cp.ckpt\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7291 - val_loss: 18.6582\n",
      "\n",
      "Epoch 00923: saving model to training_1\\cp.ckpt\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 19.7187 - val_loss: 18.6937\n",
      "\n",
      "Epoch 00924: saving model to training_1\\cp.ckpt\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7399 - val_loss: 18.5583\n",
      "\n",
      "Epoch 00925: saving model to training_1\\cp.ckpt\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7601 - val_loss: 18.5786\n",
      "\n",
      "Epoch 00926: saving model to training_1\\cp.ckpt\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 19.7499 - val_loss: 18.5990\n",
      "\n",
      "Epoch 00927: saving model to training_1\\cp.ckpt\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7396 - val_loss: 18.6268\n",
      "\n",
      "Epoch 00928: saving model to training_1\\cp.ckpt\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7293 - val_loss: 18.6569\n",
      "\n",
      "Epoch 00929: saving model to training_1\\cp.ckpt\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7189 - val_loss: 18.6925\n",
      "\n",
      "Epoch 00930: saving model to training_1\\cp.ckpt\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7382 - val_loss: 18.5576\n",
      "\n",
      "Epoch 00931: saving model to training_1\\cp.ckpt\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7603 - val_loss: 18.5778\n",
      "\n",
      "Epoch 00932: saving model to training_1\\cp.ckpt\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 19.7501 - val_loss: 18.5982\n",
      "\n",
      "Epoch 00933: saving model to training_1\\cp.ckpt\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7398 - val_loss: 18.6258\n",
      "\n",
      "Epoch 00934: saving model to training_1\\cp.ckpt\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 19.7295 - val_loss: 18.6557\n",
      "\n",
      "Epoch 00935: saving model to training_1\\cp.ckpt\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7190 - val_loss: 18.6912\n",
      "\n",
      "Epoch 00936: saving model to training_1\\cp.ckpt\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7365 - val_loss: 18.5569\n",
      "\n",
      "Epoch 00937: saving model to training_1\\cp.ckpt\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7604 - val_loss: 18.5771\n",
      "\n",
      "Epoch 00938: saving model to training_1\\cp.ckpt\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7502 - val_loss: 18.5975\n",
      "\n",
      "Epoch 00939: saving model to training_1\\cp.ckpt\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7400 - val_loss: 18.6248\n",
      "\n",
      "Epoch 00940: saving model to training_1\\cp.ckpt\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7296 - val_loss: 18.6545\n",
      "\n",
      "Epoch 00941: saving model to training_1\\cp.ckpt\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7192 - val_loss: 18.6900\n",
      "\n",
      "Epoch 00942: saving model to training_1\\cp.ckpt\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7347 - val_loss: 18.5561\n",
      "\n",
      "Epoch 00943: saving model to training_1\\cp.ckpt\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7606 - val_loss: 18.5764\n",
      "\n",
      "Epoch 00944: saving model to training_1\\cp.ckpt\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7504 - val_loss: 18.5967\n",
      "\n",
      "Epoch 00945: saving model to training_1\\cp.ckpt\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7401 - val_loss: 18.6238\n",
      "\n",
      "Epoch 00946: saving model to training_1\\cp.ckpt\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 19.7298 - val_loss: 18.6533\n",
      "\n",
      "Epoch 00947: saving model to training_1\\cp.ckpt\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7194 - val_loss: 18.6888\n",
      "\n",
      "Epoch 00948: saving model to training_1\\cp.ckpt\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7330 - val_loss: 18.5554\n",
      "\n",
      "Epoch 00949: saving model to training_1\\cp.ckpt\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7607 - val_loss: 18.5756\n",
      "\n",
      "Epoch 00950: saving model to training_1\\cp.ckpt\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7505 - val_loss: 18.5960\n",
      "\n",
      "Epoch 00951: saving model to training_1\\cp.ckpt\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7403 - val_loss: 18.6229\n",
      "\n",
      "Epoch 00952: saving model to training_1\\cp.ckpt\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7299 - val_loss: 18.6521\n",
      "\n",
      "Epoch 00953: saving model to training_1\\cp.ckpt\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 19.7195 - val_loss: 18.6876\n",
      "\n",
      "Epoch 00954: saving model to training_1\\cp.ckpt\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 19.7321 - val_loss: 18.6181\n",
      "\n",
      "Epoch 00955: saving model to training_1\\cp.ckpt\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7316 - val_loss: 18.6461\n",
      "\n",
      "Epoch 00956: saving model to training_1\\cp.ckpt\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7212 - val_loss: 18.6816\n",
      "\n",
      "Epoch 00957: saving model to training_1\\cp.ckpt\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7282 - val_loss: 18.6134\n",
      "\n",
      "Epoch 00958: saving model to training_1\\cp.ckpt\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7333 - val_loss: 18.6413\n",
      "\n",
      "Epoch 00959: saving model to training_1\\cp.ckpt\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7229 - val_loss: 18.6755\n",
      "\n",
      "Epoch 00960: saving model to training_1\\cp.ckpt\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 19.7244 - val_loss: 18.6086\n",
      "\n",
      "Epoch 00961: saving model to training_1\\cp.ckpt\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7349 - val_loss: 18.6366\n",
      "\n",
      "Epoch 00962: saving model to training_1\\cp.ckpt\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 19.7245 - val_loss: 18.6695\n",
      "\n",
      "Epoch 00963: saving model to training_1\\cp.ckpt\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 19.7206 - val_loss: 18.6039\n",
      "\n",
      "Epoch 00964: saving model to training_1\\cp.ckpt\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 19.7366 - val_loss: 18.6318\n",
      "\n",
      "Epoch 00965: saving model to training_1\\cp.ckpt\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7262 - val_loss: 18.6635\n",
      "\n",
      "Epoch 00966: saving model to training_1\\cp.ckpt\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7167 - val_loss: 18.5991\n",
      "\n",
      "Epoch 00967: saving model to training_1\\cp.ckpt\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 19.7382 - val_loss: 18.6270\n",
      "\n",
      "Epoch 00968: saving model to training_1\\cp.ckpt\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7279 - val_loss: 18.6575\n",
      "\n",
      "Epoch 00969: saving model to training_1\\cp.ckpt\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7175 - val_loss: 18.6930\n",
      "\n",
      "Epoch 00970: saving model to training_1\\cp.ckpt\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7394 - val_loss: 18.5576\n",
      "\n",
      "Epoch 00971: saving model to training_1\\cp.ckpt\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7589 - val_loss: 18.5778\n",
      "\n",
      "Epoch 00972: saving model to training_1\\cp.ckpt\n",
      "Epoch 973/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7486 - val_loss: 18.5982\n",
      "\n",
      "Epoch 00973: saving model to training_1\\cp.ckpt\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7384 - val_loss: 18.6261\n",
      "\n",
      "Epoch 00974: saving model to training_1\\cp.ckpt\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7280 - val_loss: 18.6563\n",
      "\n",
      "Epoch 00975: saving model to training_1\\cp.ckpt\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7176 - val_loss: 18.6918\n",
      "\n",
      "Epoch 00976: saving model to training_1\\cp.ckpt\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7378 - val_loss: 18.5569\n",
      "\n",
      "Epoch 00977: saving model to training_1\\cp.ckpt\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7590 - val_loss: 18.5771\n",
      "\n",
      "Epoch 00978: saving model to training_1\\cp.ckpt\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7488 - val_loss: 18.5975\n",
      "\n",
      "Epoch 00979: saving model to training_1\\cp.ckpt\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 19.7385 - val_loss: 18.6251\n",
      "\n",
      "Epoch 00980: saving model to training_1\\cp.ckpt\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7282 - val_loss: 18.6551\n",
      "\n",
      "Epoch 00981: saving model to training_1\\cp.ckpt\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7178 - val_loss: 18.6906\n",
      "\n",
      "Epoch 00982: saving model to training_1\\cp.ckpt\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7361 - val_loss: 18.5562\n",
      "\n",
      "Epoch 00983: saving model to training_1\\cp.ckpt\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7591 - val_loss: 18.5764\n",
      "\n",
      "Epoch 00984: saving model to training_1\\cp.ckpt\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 19.7489 - val_loss: 18.5967\n",
      "\n",
      "Epoch 00985: saving model to training_1\\cp.ckpt\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 19.7387 - val_loss: 18.6242\n",
      "\n",
      "Epoch 00986: saving model to training_1\\cp.ckpt\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7283 - val_loss: 18.6540\n",
      "\n",
      "Epoch 00987: saving model to training_1\\cp.ckpt\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 19.7179 - val_loss: 18.6895\n",
      "\n",
      "Epoch 00988: saving model to training_1\\cp.ckpt\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.7345 - val_loss: 18.5554\n",
      "\n",
      "Epoch 00989: saving model to training_1\\cp.ckpt\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 19.7593 - val_loss: 18.5757\n",
      "\n",
      "Epoch 00990: saving model to training_1\\cp.ckpt\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7491 - val_loss: 18.5960\n",
      "\n",
      "Epoch 00991: saving model to training_1\\cp.ckpt\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7388 - val_loss: 18.6232\n",
      "\n",
      "Epoch 00992: saving model to training_1\\cp.ckpt\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7285 - val_loss: 18.6528\n",
      "\n",
      "Epoch 00993: saving model to training_1\\cp.ckpt\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 19.7181 - val_loss: 18.6883\n",
      "\n",
      "Epoch 00994: saving model to training_1\\cp.ckpt\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7328 - val_loss: 18.5547\n",
      "\n",
      "Epoch 00995: saving model to training_1\\cp.ckpt\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7594 - val_loss: 18.5750\n",
      "\n",
      "Epoch 00996: saving model to training_1\\cp.ckpt\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 19.7492 - val_loss: 18.5953\n",
      "\n",
      "Epoch 00997: saving model to training_1\\cp.ckpt\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 19.7389 - val_loss: 18.6223\n",
      "\n",
      "Epoch 00998: saving model to training_1\\cp.ckpt\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 19.7286 - val_loss: 18.6517\n",
      "\n",
      "Epoch 00999: saving model to training_1\\cp.ckpt\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 19.7182 - val_loss: 18.6871\n",
      "\n",
      "Epoch 01000: saving model to training_1\\cp.ckpt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What problems, other than computational and memory load, can occur due to a too complex\n",
    "# network architecture? - overfitting 1b\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(8, activation=None, input_shape=[1]),\n",
    "    layers.Dense(8, activation=None),\n",
    "    layers.Dense(8, activation=None),\n",
    "    layers.Dense(1, activation=None)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.SGD(0.001))\n",
    "\n",
    "prediction_untrained = model.predict(test_x)\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    verbose=1, epochs=1000, validation_data=(test_x, test_y), callbacks=[cp_callback])\n",
    "\n",
    "prediction_trained = model.predict(test_x)\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax1.set_title('Test data')\n",
    "ax1.plot(test_x, test_y)\n",
    "ax2.set_title('Prediction on test set')\n",
    "ax2.plot(test_x, prediction_untrained, test_x, prediction_trained)\n",
    "ax2.legend(['Untrained prediction', 'Trained prediction'], loc='upper left')\n",
    "plt.savefig('test_and_prediction_on_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c93bc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax1.set_title('Test data')\n",
    "ax1.plot(test_x, test_y)\n",
    "ax2.set_title('Prediction on test set')\n",
    "ax2.plot(test_x, prediction_untrained)\n",
    "#ax2.legend(['Untrained prediction', 'Trained prediction'], loc='upper left')\n",
    "plt.savefig('test_and_prediction_on_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79de5dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Train and validation losses')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
    "plt.savefig('Train_and_val_losses.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c0d6a390",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-a5669eb10a47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdense_layer_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdense_layer_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_layer_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#IGNORE FROM HERE ON\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(train_x.shape[1],))\n",
    "dense_layer_1 = Dense(100, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(50, activation='relu')(dense_layer_1)\n",
    "dense_layer_3 = Dense(25, activation='relu')(dense_layer_2)\n",
    "output = Dense(1)(dense_layer_3)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "model.compile(loss=\"mean_squared_error\" , optimizer=\"SGD\", metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c46cef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of an optimizer is to find the best fit for the given variables balbalbla\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer = tf.optimizers.SGD(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b8cb96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9461bec43bc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='weights.ckpt',\n\u001b[0m\u001b[0;32m      9\u001b[0m                                                  \u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                  verbose=1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Save weights during training \n",
    "\n",
    "import os\n",
    "\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath='weights.ckpt',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "prediction = model.predict(test_x)\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax1.set_title('Test data')\n",
    "ax1.plot(test_x, test_y)\n",
    "ax2.set_title('Prediction on test set')\n",
    "ax2.plot(test_x, prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac3b3186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1723fecc148>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = model.predict(test_x)\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax1.set_title('Test data')\n",
    "ax1.plot(test_x, test_y)\n",
    "ax2.set_title('Prediction on train set')\n",
    "ax2.plot(test_x, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0706a1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 292ms/step - loss: nan\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: nan\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: nan\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: nan\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: nan\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 212/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: nan\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 940us/step - loss: nan\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: nan\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 317/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: nan\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: nan\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 422/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: nan\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 632/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: nan\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: nan\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 997us/step - loss: nan\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 947/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 983us/step - loss: nan\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: nan\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    verbose=1, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f78620c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 30.1817\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 26.3149\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 23.4406\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 20.3991\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8318\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7872\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7449\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9467\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9363\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8980\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8575\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8146\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7691\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8099\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9539\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9168\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8775\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8360\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7919\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7451\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9277\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9346\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8966\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8562\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8135\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7681\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7928\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9512\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9142\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8751\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8337\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7897\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7430\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9113\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9311\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8932\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8530\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8103\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7651\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7800\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9470\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9101\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8711\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8297\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7859\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7393\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9008\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9264\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8885\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8484\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8058\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7606\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7732\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9418\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9049\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8659\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8246\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7808\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7342\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8970\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9208\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8828\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8427\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8001\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7549\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7730\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.9357\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8988\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8597\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8184\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7745\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7279\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8998\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9142\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8762\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8360\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7933\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7480\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7790\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9287\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8917\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8526\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8111\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7671\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7203\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9091\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9068\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8686\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8282\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7854\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7400\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 19.7912\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9209\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8838\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8444\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8027\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7585\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7115\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9246\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.8984\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8601\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8195\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7764\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.7307\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8093\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9122\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8748\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8353\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7933\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7488\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7121\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8024\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7585\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7118\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.8849\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8968\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8587\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8183\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7755\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7300\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7751\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9107\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8294\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7874\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7428\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7079\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7961\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7521\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7054\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8836\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8901\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8519\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8114\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7685\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7229\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7774\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9037\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8221\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.7800\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7352\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7071\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7885\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7443\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6973\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8904\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8823\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8439\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8032\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7601\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7143\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7874\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8945\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8569\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8172\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7750\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7302\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6985\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7832\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7389\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6919\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8796\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8764\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8380\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7972\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7540\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7081\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7809\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8900\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8071\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7645\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7194\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7109\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9097\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.8164\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7746\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7302\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6830\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8865\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8677\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8291\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7881\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7447\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6985\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7908\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8797\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7975\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.7547\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7093\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7232\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.8986\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8063\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7643\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7196\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6775\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7716\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.7274\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6804\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.8507\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8633\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8247\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7837\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7404\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6948\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7620\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8807\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7929\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7502\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.7048\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6986\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8984\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8011\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7590\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7143\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6668\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.8802\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8519\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8130\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7718\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7280\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6814\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7887\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8651\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7799\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7367\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6908\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7260\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8830\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7862\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7420\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6951\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7108\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8995\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7938\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7503\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7040\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6671\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7570\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7112\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6625\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8554\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8504\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 999us/step - loss: 19.8103\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7679\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7230\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6752\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7739\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8728\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7755\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7311\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6840\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7165\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8884\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7826\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7388\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6923\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6664\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7451\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6990\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6500\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8670\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8383\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7980\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7553\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7100\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6618\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7897\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8587\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7623\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7176\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6700\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7352\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8735\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7689\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7247\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6778\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6830\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8876\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7752\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7315\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6851\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6485\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7372\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6912\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6422\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8402\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8344\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7439\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6984\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6501\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7872\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8487\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7502\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7052\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6575\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7366\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8624\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7562\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7117\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6644\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6882\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8754\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7618\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7177\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6710\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6468\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7230\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6766\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6300\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7281\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6820\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6330\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8140\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8311\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7339\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6883\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6398\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7662\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8439\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7394\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6943\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6462\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7200\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8563\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7446\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6998\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6523\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6759\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8681\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7494\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7051\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6580\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6366\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7098\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6630\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6211\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7143\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6678\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6184\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8124\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8204\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7194\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6733\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6243\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7683\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8322\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7241\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6784\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6298\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7263\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8433\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7285\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6832\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6350\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6863\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8538\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 924us/step - loss: 19.7326\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6877\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6398\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6476\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8640\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7364\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6919\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6444\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.6184\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6959\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6487\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6040\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6998\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6529\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6030\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7957\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8142\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7043\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6578\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6081\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7563\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8238\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7077\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6614\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6123\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7191\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8351\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7118\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6658\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6169\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6820\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8444\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7151\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6694\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6208\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6468\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8535\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7181\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6727\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6244\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6133\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8621\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7209\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6757\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6276\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5957\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6792\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6313\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5820\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6825\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6349\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5843\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7729\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8073\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6857\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6382\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5879\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7384\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8161\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.6886\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6415\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.5914\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7039\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8249\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6913\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6444\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5946\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6713\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8331\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6938\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6471\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5975\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6399\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8443\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6570\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6081\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5840\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6599\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6111\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5715\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6625\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6139\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5622\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7770\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7932\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6648\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6167\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.5652\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.7443\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8014\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6671\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6193\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5682\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7109\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8098\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6692\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6216\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5709\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6793\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8224\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6315\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5815\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6130\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8516\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6410\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5918\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.5628\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6434\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5943\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5503\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.6460\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5969\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5448\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7515\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7876\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6479\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5992\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5474\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7183\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8002\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6094\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5583\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6504\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8301\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6191\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5688\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5847\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8598\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6288\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5792\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5416\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6308\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5814\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5290\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6328\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5835\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5309\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7248\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7948\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5940\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5423\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6530\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8262\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6044\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5534\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5823\n",
      "Epoch 502/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8573\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6142\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5639\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5320\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6160\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5658\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5194\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6177\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5678\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5144\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7220\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7936\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5785\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5260\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6478\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8262\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5891\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5378\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5723\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8592\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5991\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5492\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5163\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6009\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5512\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.5003\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6031\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5535\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5008\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6903\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8063\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5659\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 19.5126\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6099\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8421\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5752\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5240\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5320\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8766\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5862\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5362\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4849\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5888\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5394\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4859\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6688\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8149\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5515\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4995\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5752\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8554\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5660\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5150\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4950\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5654\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5164\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4694\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5703\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5198\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4660\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6522\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8254\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5345\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4798\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5534\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8685\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5444\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4926\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4705\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5474\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4960\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4434\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5558\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4434\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6533\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8233\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5133\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4602\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5299\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8804\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5886\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8454\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5156\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4633\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4751\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9209\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5350\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8636\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5177\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4659\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4342\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5285\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4185\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5383\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4174\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6089\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8312\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4929\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.4394\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4868\n",
      "Epoch 602/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9044\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.5491\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8511\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4949\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4420\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4306\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5059\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4112\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5176\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3933\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6165\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8195\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4645\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4105\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.4803\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9050\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5387\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8476\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4709\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4235\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9413\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4746\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8876\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5231\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8420\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4667\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4059\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.9334\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4585\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8788\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5092\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8351\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4612\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3976\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9229\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4487\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8700\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4968\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8289\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4593\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4064\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.9191\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4365\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8643\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.4844\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8243\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4494\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3793\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4638\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.3547\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4797\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5073\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.8109\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4242\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3969\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8923\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4636\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8269\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4395\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3499\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4575\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5345\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7970\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3999\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4221\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8678\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4945\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8046\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4142\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3709\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8931\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4197\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.8414\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4664\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8031\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4119\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3481\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8961\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3902\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.85 - 0s 3ms/step - loss: 19.8508\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4247\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8174\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4755\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7851\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3952\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3481\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8782\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4306\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7997\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4070\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5523\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7429\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3558\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4225\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7944\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4009\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5517\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7400\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3445\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4197\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7950\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.4742\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7616\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3689\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5785\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7145\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3158\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4568\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7648\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3489\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6032\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6963\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.2997\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4637\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7563\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3294\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 983us/step - loss: 19.3604\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.8173\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4041\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7797\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4395\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7522\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3514\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5420\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7050\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.2860\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4210\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7539\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 781us/step - loss: 19.3358\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5519\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6919\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2778\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6611\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6466\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.2283\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5047\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7106\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.2654\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6543\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6379\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2284\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4597\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7246\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2657\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6218\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6434\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.2167\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4327\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7249\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4879\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6879\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.2760\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5481\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6690\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.1980\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6990\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5918\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1556\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4530\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7428\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5742\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6480\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2215\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6231\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.6185\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1723\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6810\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5883\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1244\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7583\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5520\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0723\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5965\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6274\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.0991\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7872\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5323\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0523\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6010\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6059\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1116\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7228\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5525\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.0407\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5778\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6054\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.0951\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7217\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5373\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0419\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8140\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4990\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.9965\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1610\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4883\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6932\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8412\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4748\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.0226\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7972\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4970\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.9883\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8516\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4516\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9642\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.1392\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4509\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6881\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6885\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5145\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0727\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6643\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5078\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0341\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7081\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4853\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9718\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.8152\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4365\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9491\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.1057\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4435\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5984\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7228\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4279\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9415\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7889\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.4189\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9193\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.9631\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6363\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5234\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.9432\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4250\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.9069\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7777\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4080\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8846\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.9174\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6483\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5055\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.9645\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3575\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.8759\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.8876\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6568\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4612\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.8929\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3781\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8579\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.7394\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3924\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8448\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8472\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.6437\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4446\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8915\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3494\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8242\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8748\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5071\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6160\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.0726\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2291\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8500\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.3528\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.8090\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.6858\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3660\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7974\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8209\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5368\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4859\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9125\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.2597\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7776\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.8194\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.4483\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5693\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.9250\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2413\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7804\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7768\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5103\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4239\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6807\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.2904\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7450\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5480\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.3731\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6983\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2679\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7342\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4976\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4034\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.8009\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.2179\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7116\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.7476\n",
      "Epoch 901/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3473\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.5204\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6771\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.2261\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6889\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4437\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3810\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.6488\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2181\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6750\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4159\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3846\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4994\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2687\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3394\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3762\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 19.26 - 0s 2ms/step - loss: 19.2666\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4548\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2252\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4122\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0683\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1423\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.6289\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.3392\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3406\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.4627\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2175\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.2318\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3649\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1686\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0363\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.5651\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.6007\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0891\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1870\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.7229\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0775\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.5544\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5030\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.5388\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1078\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.6401\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.5016\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 23.9562\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2398\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6244\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.1680\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.5963\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.5772\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1539\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.3076\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.4569\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.0784\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.5337\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1987\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.2086\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2701\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1667\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1462\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9074\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.4895\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3141\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.5043\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9942\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.4878\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.4931\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.0006\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6866\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7335\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9021\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7511\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.8383\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.5561\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.0606\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7024\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.8486\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.4077\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.2883\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4508\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.9685\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.1647\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7987\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.3995\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1755\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1424\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7448\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.3942\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.2701\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6730\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8231\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.3272\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.3892\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7799\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.6469\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 18.5230\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.8867\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 19.7501\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 22.2411\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.5803\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 24.2864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ca501817c8>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[1]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.SGD(0.01))\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_x, train_y,\n",
    "    verbose=1, epochs=1000)\n",
    "\n",
    "prediction = model.predict(test_x)\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax1.set_title('Test data')\n",
    "ax1.plot(test_x, test_y)\n",
    "ax2.set_title('Prediction on train set')\n",
    "ax2.plot(test_x, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "976d80f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1281.5227\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24576.0820\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1671.3152\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1667.0151\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1663.7500\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1660.4973\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1657.2562\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1654.0266\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1650.8076\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1647.5989\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1644.3997\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1641.2089\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1638.0267\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1634.8519\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1631.6836\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1628.5212\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1625.3638\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1622.2103\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1619.0597\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1615.9111\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1612.7629\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1609.6143\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1606.4634\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1603.3085\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1600.1481\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1596.9801\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1593.8030\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1590.6134\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1587.4098\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1584.1886\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1580.9475\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1577.6825\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1574.3905\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1571.0669\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1567.7080\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1564.3082\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1560.8629\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1557.3661\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1553.8115\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1550.1924\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1546.5007\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1542.7292\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1538.8684\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1534.9087\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1530.8398\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1526.6500\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1522.3275\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1517.8584\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1513.2288\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1508.4230\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1503.4243\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1498.2152\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1492.7767\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1487.0887\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1481.1293\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1474.8766\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1468.3064\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1461.3944\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1454.1145\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1446.4407\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1438.3456\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1429.8022\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1420.7830\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1411.2616\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1401.2119\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1390.6100\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1379.4336\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1367.6631\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1355.2834\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1342.2834\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1328.6577\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1314.4073\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1299.5411\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1284.0756\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1268.0375\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1251.4626\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1234.3983\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1216.9019\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1199.0421\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1180.8981\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1162.5587\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1144.1215\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1125.6909\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1107.3765\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1089.2899\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1071.5439\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1054.2472\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1037.5037\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1021.4087\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1006.0468\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 991.4899\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 977.7953\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 965.0051\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 953.1454\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 942.2271\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 932.2461\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 923.1849\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 915.0142\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 907.6945\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 901.1790\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 895.4144\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 890.3439\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 885.9092\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 882.0508\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 878.7107\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 875.8332\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 873.3650\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 871.2570\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 869.4636\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 867.9434\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 866.6590\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 865.5774\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 864.6691\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 863.9086\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 863.2732\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 862.7437\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 862.3032\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 861.9375\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 861.6346\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 861.3839\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 861.1767\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 861.0059\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.8651\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.7491\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.6539\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.5756\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.5112\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.4584\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.4153\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.3800\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.3510\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.3272\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.3079\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2921\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2790\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2684\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2597\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 840us/step - loss: 860.2527\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2469\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2422\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 860.2383\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2352\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2327\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2307\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2290\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2275\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2265\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2255\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2248\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2241\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2238\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2233\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2229\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2227\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2224\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2223\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2220\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2219\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2218\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2219\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2217\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2216\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2217\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2216\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 983us/step - loss: 860.2215\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 197/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2216\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2213\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 860.221 - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 860.2214\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 860.2215\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2213\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2216\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2213\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 998us/step - loss: 860.2215\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 860.2214\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2216\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2213\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 589/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 817us/step - loss: 860.2215\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 860.2215\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 860.2215\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 848us/step - loss: 860.2214\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2213\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 996us/step - loss: 860.2215\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 860.2214\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2216\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 988us/step - loss: 860.2215\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2215\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 758us/step - loss: 860.2215\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 995us/step - loss: 860.2214\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 905us/step - loss: 860.2215\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2213\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2215\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2213\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 860.2214\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2214\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 690us/step - loss: 860.2214\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2216\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2214\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2214\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 860.2215\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 860.2215\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 860.2215\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 860.2214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca4eea8cc8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "##Exercise B\n",
    "# Train a model \n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu, input_shape=[1]),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "# Fit a model\n",
    "optimizer = tf.keras.optimizers.SGD(0.001)\n",
    "model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "model.fit(train_x,train_y,epochs=1000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83de5ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABKWElEQVR4nO3dd3yV5fn48c+VvXcCGRBWBlFWQDbIEEVRUERRqWKtWqvWtra12tat/er32zqq/Wm1blEQVFC0OBgiKhtkJoSRSUL2Tsi6f388T2JC9jwj9/v1yis55xnnOifPuc597ud+rluUUmiapmn2xcHSAWiapmk9Tyd3TdM0O6STu6Zpmh3SyV3TNM0O6eSuaZpmh3Ry1zRNs0M6udsREUkWkYssHYdmvUTkTRF5wvx7hogkdnE/L4vIgz0bndaTdHLvISJS2uinTkQqGt1e1oX9bRGRW3sjVnP/SkRG9Nb+ta4zP6Trj58zZkL26unHUUp9q5SK6UA8N4vItnO2vUMp9XhPx9STeuo9JCKzRCS9J2JqYd+91iDTyb2HKKW86n+AVOCKRvetsHR8ms25wjyW4oEJwF/PXUFEnPo8Ks1m6OTey0TEQUTuF5ETIpInIh+ISIC5zE1E3jXvLxSRXSIyQESeBGYAL5qttxdb2feNIpJibv+Xc5ZNFJEfzP1misiLIuJiLttqrvajuf+lIuIvIutFJEdECsy/I3rxpdE6QCmVAfwXOB8avnHdJSJJQJJ53+Uist/8X38vIqPrtxeRcSKyV0RKRGQV4NZoWZMWqYgMEpGPzGMgzzxmRgIvA1PMY6XQXLehe8e8fZuIHBeRfBH5RETCGi1TInKHiCSZMf5LRKSl5ysiriLynIicNn+eExHXxvGKyO9FJNs8rn/eyn5afA+JSKyIfGXGmSgi1zba5jIROWK+Vhki8gcR8TRf/7BG38TDWni8Zts2Wtbi/0dE3gEGA5+a+72vpefSZUop/dPDP0AycJH592+A7UAE4Ar8G3jfXPZL4FPAA3AExgM+5rItwK1tPEYcUArMNPf7DFDT6HHHA5MBJ2AIcBT4baPtFTCi0e1A4GozFm9gNbDW0q9lf/w55/gZBBwGHm/0f/sKCADcgXFANjDJPIaWm9u7Ai5ACvA7wBlYAlQDT5j7mgWkm387Aj8CzwKeGB8C081lNwPbzonxzUb7mQPkYnzLcAVeALaec6ytB/wwklkOML+V5/6Y+X4JAYKB7xs991nmMf6Y+XwuA8oB/1b21eQ9ZD6vNODn5vtinBl3nLk8E5hh/u0PxJ/7OrXxP2tt21b/P+f+r3v8OLL0gWyPP+e8OY8CcxstCzXfYE7ALebBO7q9A7OF5Q8BKxvd9gSqWjtQgN8CHze63SS5t7D+WKDA0q9lf/wxj59SoBAjOf8/wL3R/21Oo3Vfqk9+je5LBC7E+OA/DUijZd/TcnKfYiZdpxbiuZm2k/trwP82WuZlHuNDGsU8vdHyD4D7W3nuJ4DLGt2+BEhuFG9F4xjNxDm5lX01eQ8BS4Fvz1nn38DD5t+pGA0un3PWaXid2viftbZtq/+fRv/rXknuulum90UCH5tfyQoxkn0tMAB4B/gCWGl+Bf1fEXHu4H7DMFohACilyoC8+tsiEm12rWSJSDHwNyCotZ2JiIeI/Nvs5ikGtgJ+IuLYqWer9ZQrlVJ+SqlIpdSdSqmKRsvSGv0dCfy+/vgyj7FBGMdHGJChzCxiSmnl8QYBKUqpmi7EGtZ4v0qpUoxjMbzROlmN/i7H+ABod1/m3427QfLOibGtfZ0rEph0zmu1DBhoLr8a49tAioh8IyJTOrjftrZt6//Tq3Ry731pwKXmG7X+x00plaGUqlZKPaqUigOmApcDN5nbtVeuMxPjIAGM5IzRtVLvJSABiFJK+QB/Blrs5zT9HogBJpnrz6zfdceeptaHGh8bacCT5xxfHkqp9zGOkfBz+rcHt7LPNGCwtHyStr1j8TRGEgPA7KcOBDLaeyLt7Qsj3tNd2A80jzsN+Oac18pLKfUrAKXULqXUIowuobUY3zBa2k/zB2p927b+Px3ad1fp5N77XgaeFJFIABEJFpFF5t+zRWSU2TouxvgqW2dudwYY1sZ+1wCXi8h0MU6UPkbT/6e3uc9SEYkFfnXO9ufu3xvjK2+hGCd8H+78U9Us4FXgDhGZJAZPEVkgIt7ADxh91PeIiLOILAYmtrKfnRgfBk+Z+3ATkWnmsjNAhHmcteR94OciMtY8+fk3YIdSKrkLz+d94K/m+yQIo/vx3S7sB5of4+uBaDEGIjibPxeIyEgRcRGRZSLiq5SqxnjvNH4vBoqIb0sP0s62bf1/Woqxx+jk3vueBz4BvhSREoyTRZPMZQMxknQxRnfNNxhdNfXbLRFj5Mo/z92pUuowcBfwHsabsgBoPBb3D8ANQAnGAbbqnF08ArxlflW8FngO4wRdrhnjhi4/Y63PKKV2A7cBL2IcA8cx+shRSlUBi83b+Rh9zh+1sp9a4ApgBEb/cbq5PsAmjJO6WSKS28K2XwMPAh9iHIvDgeu6+JSeAHYDB4CDwF7zvq5o8h5SSpUAF5uxncboKnoa4yQwwI1AstkteQdGlw1KqQSMD52T5vulpS6V1rZt9f9j+h+MD7PCxiNseoI07Y7TNE3T7IFuuWuaptkhndw1TdPskE7umqZpdkgnd03TNDtkFYWHgoKC1JAhQywdhman9uzZk6uUCrbEY+tjW+tNbR3bVpHchwwZwu7duy0dhmanRKS1qzJ7nT62td7U1rGtu2U0TdPskFW03DXN2ohIMsYFYLVAjVJqgnnl7iqMKpvJwLVKqQJLxahpbdEtd01r3Wyl1Fil1ATz9v3ARqVUFLDRvK1pVkm33DWt4xZhlH8FeAujpOyfOruT6upq0tPTqays7LnINLvj5uZGREQEzs4dLRTblE7umtYyhVEPSAH/Vkq9AgxQSmWay7MwyjY3IyK3A7cDDB7cvAhjeno63t7eDBkyBGl5QiKtn1NKkZeXR3p6OkOHDu3SPnS3jKa1bLpSKh64FLhLRGY2XmjWSG+xMJNS6hWl1ASl1ITg4Oaj1CorKwkMDNSJXWuViBAYGNitb3c6uWtaC5QxdylKqWzgY4xSuWdEJBTA/J3d1f3rxK61p7vHiE7ums1LOlPCk58doacqnJo1t73r/8YoE3sIo3TzcnO15cC6HnlATWtNVSkc+6JLm+rkrtm0l7acYP7z37JyVxonc8t6arcDgG0i8iPGJBafKaU2AE8B80QkCbjIvG1zkpOTOf/885vc98gjj/D3v/+9ze3279/P559/3unHO336NEuWLOn0di3ZsmULl19+eY/sqy2NX4+HHnqIr7/+utV1z31dPvnkE556qgcOjcpiKC+A3a9DFxou+oSqZrNyS8/yzFeJXBgdzP8tGU2gl2v7G3WAUuokMKaF+/OAuT3yIDZo//797N69m8suu6zZspqaGpycWk4nYWFhrFmzprfDa1fDxNEOnWvTPvbYY20uP/d1WbhwIQsXLuxynABUl0PBKXB0hqv/A13ootEtd81mfbA7jepaxZ8vi+2xxK7BrFmz+NOf/sTEiROJjo7m22+/paqqioceeohVq1YxduxYVq1axSOPPMKNN97ItGnTuPHGG0lOTmbGjBnEx8cTHx/P999/DzT9pvDmm2+yePFi5s+fT1RUFPfdd1/D43755ZdMmTKF+Ph4rrnmGkpLSwHYsGEDsbGxxMfH89FHLU4kxZtvvsmiRYuYNWsWUVFRPProow2PHRMTw0033cT5559PWloa//d//8cFF1zA6NGjefjhn2aTfPLJJ4mOjmb69OkkJiY23H/zzTc3fDjt2rWLqVOnMmbMGCZOnEhRUVGz1+XNN9/k7rvvbnj8OXPmMHr0aObOnUtqamrDPu+55x6mTp3KsGHDmn741VRB3kkQR/AMBldvukK33DWbVFuneG9HKpOHBTAipGsHvzV49NPDHDld3KP7jAvz4eErzuvWPmpqati5cyeff/45jz76KF9//TWPPfYYu3fv5sUXXwSMrosjR46wbds23N3dKS8v56uvvsLNzY2kpCSuv/76Fuvq7N+/n3379uHq6kpMTAy//vWvcXd354knnuDrr7/G09OTp59+mmeeeYb77ruP2267jU2bNjFixAiWLl3abH/1du7cyaFDh/Dw8OCCCy5gwYIFBAUFkZSUxFtvvcXkyZP58ssvSUpKYufOnSilWLhwIVu3bsXT05OVK1eyf/9+ampqiI+PZ/z48U32X1VVxdKlS1m1ahUXXHABxcXFeHh4NHtd3nzzzYZtfv3rX7N8+XKWL1/O66+/zj333MPatWsByMzMZNu2bSQkJLBw4UKj66quFvJPgqqFoGgoSO7y/1And80m7UstIL2ggj9eEmPpUGxOa6MwGt+/ePFiAMaPH09ycnKr+1q4cCHu7u6AcXHW3Xffzf79+3F0dOTYsWMtbjN37lx8fY25puPi4khJSaGwsJAjR44wbZoxJ3dVVRVTpkwhISGBoUOHEhUVBcDPfvYzXnnllRb3O2/ePAIDAxvi37ZtG1deeSWRkZFMnjwZML4dfPnll4wbNw6A0tJSkpKSKCkp4aqrrsLDw6PheZ0rMTGR0NBQLrjgAgB8fHxafV3q/fDDDw3fNm688cYm31SuvPJKHBwciIuL48yZM6DqjK6YmkoIGAbO7u3uvy3tJncReR24HMhWSp1v3tdijQ0xjo7ngcuAcuBmpdTebkWoaS3Ym2qUdJk2IsjCkXRPd1vYXREYGEhBQdOSOPn5+U0ulnF1Nbq5HB0dqampaXVfnp6eDX8/++yzDBgwgB9//JG6ujrc3Nxa3KZ+3433r5Ri3rx5vP/++03W3b9/f4ef17kfWvW3G8eolOKBBx7gl7/8ZZN1n3vuuQ4/Tk9p/DoopaAoHc6WgO8gcGv/g6M9HelzfxOYf859rdXYuBSIMn9uB17qdoSa1oL9aYVE+LsTpPvaO83Ly4vQ0FA2bdoEGIl9w4YNTJ8+vc3tvL29KSkpaXV5UVERoaGhODg48M4771BbW9vhmCZPnsx3333H8ePHASgrK+PYsWPExsaSnJzMiRMnAJol/8a++uor8vPzqaioYO3atQ3fAhq75JJLeP311xv68zMyMsjOzmbmzJmsXbuWiooKSkpK+PTTT5ttGxMTQ2ZmJrt27QKgpKSEmpqaNl+XqVOnsnLlSgBWrFjBjBkzWoleQXkeeA0Az55psLSb3JVSW4H8c+5ehFFbA/P3lY3uf1sZtgN+9Rd9aFpP2p9ayNhBfpYOw2a9/fbbPP7444wdO5Y5c+bw8MMPM3z48Da3mT17NkeOHGk4cXiuO++8k7feeosxY8aQkJDQpMXcnuDgYN58802uv/56Ro8e3dAl4+bmxiuvvMKCBQuIj48nJCSk1X1MnDiRq6++mtGjR3P11VczYcKEZutcfPHF3HDDDUyZMoVRo0axZMkSSkpKiI+PZ+nSpYwZM4ZLL720oeulMRcXF1atWsWvf/1rxowZw7x586isrGzzdXnhhRd44403GD16NO+88w7PP/9888DL842hju7+4N2D6bJ+eFBbPxjdL4ca3S5s9LfU3wbWY1y2Xb9sIzChvf2PHz9eaVpHnSmqUJF/Wq9e3XqiQ+sDu1UHjvPe+Gnp2D5y5Ejnn7TWpjfeeEPdddddlg6j8yqLlcrYp1TOMaXqapstbu9YaevY7vZQSPMBOj3CXkRuF5HdIrI7Jyenu2Fo/ci+tEIAxg32t2wgmtYd1ZWQfwqcXCBgKEjPjkzv6t5aq7GRAQxqtF6EeV8zqp3iSprWmv1phTg7CueFdf+kk2Yfbr755oahiDahthryTxgXJwUMB4eeH7jY1eTeWo2NT4CbxDAZKFI/lUjVtB6RdKaEYUFeuDk7WjoUTeu8+rHstTXGkEen3hkU0JGhkO9jTFAQJCLpwMMYNTU+EJFfACnAtebqn2MMgzyOMRTy570Qs9bPncwtI2aA7V64pPVjSkFBilFewH8YuHT8pHNntZvclVLXt7KoWY0Ns//9ru4GpWmtqamtIzWvnPnnDbR0KJrWecUZcLYIfCLA3bdXH0rXltFsSlpBBTV1iqFBvdfi0bReUZoNZTlGvRiv3j/PqJO7ZlNO5RoXnwwL9rJwJLYrLy+PsWPHMnbsWAYOHEh4eHjD7aqqqja33b17N/fcc0+PxNG4wFZvalz469Zbb+XIkSOtrrtly5aGgmcAL7/8Mm+//Xb3g6goNFrtbr7gE979/XWAri2j2ZSTOUbN9mG65d5lgYGBDZf1P/LII3h5efGHP/yhYXlb5XsnTJjQ4sVBfa2tGNvyn//8p83lW7ZswcvLi6lTpwJwxx13dCm+JqrKjAJgzh7gF9ml8r1doVvumk05lVuGn4cz/p4ulg7Frtx8883ccccdTJo0ifvuu4+dO3cyZcoUxo0bx9SpUxtK4DaeLOORRx7hlltuYdasWQwbNox//vOfDft79913mThxImPHjuWXv/xlQymCN954g+joaCZOnMh3333XYiz1pYSnTJlCVFQUr776asNjz5gxg4ULFxIXF0dtbS1//OMfG8r3/vvf/waMCzPvvvtuYmJiuOiii8jO/mk2xFmzZjVUqtywYQPx8fGMGTOGuXPnkpyczMsvv8yzzz7L2LFj+fbbb5tM2rF//34mT57M6NGjueqqqxrq87RUIrlBzVljZIyjszEyxqHvRnjplrtmU07lltlXf/t/74esgz27z4Gj4NLOzwSUnp7O999/j6OjI8XFxXz77bc4OTnx9ddf8+c//5kPP/yw2TYJCQls3ryZkpISYmJi+NWvfsXx48dZtWoV3333Hc7Oztx5552sWLGCefPm8fDDD7Nnzx58fX2ZPXt2Q3XGcx04cIDt27dTVlbGuHHjWLBgAQB79+7l0KFDDB06lFdeeQVfX1927drF2bNnmTZtGhdffDH79u0jMTGRI0eOcObMGeLi4rjlllua7D8nJ4fbbruNrVu3MnToUPLz8wkICOCOO+5o8k1m48aNDdvcdNNNvPDCC1x44YU89NBDPProow0Fx1oqkUxtDeSdMEbIBA43Enwf0sldsymncsuYMjzQ0mHYpWuuuQZHR6NlWVRUxPLly0lKSkJEqK6ubnGbBQsW4OrqiqurKyEhIZw5c4aNGzeyZ8+ehvosFRUVhISEsGPHDmbNmkX9RYtLly5ttSzwokWLcHd3x93dndmzZ7Nz5078/PyYOHFiQ/XKL7/8kgMHDjT0pxcVFZGUlMTWrVu5/vrrcXR0JCwsjDlz5jTb//bt25k5c2bDvgICAtp8bYqKiigsLOTCCy8EYPny5VxzzTUNy5uVSFZ1UHASaqsgcAQ4t1whszfp5K7ZjMrqWjKLKhkSaEct9y60sHtL40JfDz74ILNnz+bjjz8mOTmZWbNmtbhNa+V7ly9fzv/8z/80Wbd+koqO6Gj53hdeeIFLLrmkybpdmee1u5qVSC5INfra/SLB1TIn/3Wfu2YzMgorAIjw794kBlr7ioqKCA83RnU0nlmoI+bOncuaNWsa+rrz8/NJSUlh0qRJfPPNN+Tl5VFdXc3q1atb3ce6deuorKwkLy+PLVu2tFil8ZJLLuGll15q+FZx7NgxysrKmDlzJqtWraK2tpbMzEw2b97cbNvJkyezdetWTp061RAjtF7W2NfXF39//4b+9HfeeaehFd+MqoXKAqPCo0fb3wh6k265azYjo8BI7uF+Orn3tvvuu4/ly5fzxBNPNPR3d1RcXBxPPPEEF198MXV1dTg7O/Ovf/2LyZMn88gjjzBlyhT8/PwYO3Zsq/sYPXo0s2fPJjc3lwcffJCwsLBmXTi33norycnJxMfHo5QiODiYtWvXctVVV7Fp0ybi4uIYPHgwU6ZMabb/4OBgXnnlFRYvXkxdXR0hISF89dVXXHHFFSxZsoR169bxwgsvNNnmrbfe4o477qC8vJxhw4bxxhtvNA+8LM8oL+ARaNRmtyAxLiq1rAkTJqiW5lrUtMbe35nKAx8dZNufZhPh79Hh7URkj1LKIuP3Wjq2jx49ysiRIy0Rjk1oaXimTagsNoqBuXobxcB6YMhje8dKW8e27pbRbEZGQQWODsJAn74/OaVpbaouN+Y/dXIH/6F9Npa9LbpbRrMZGYUVDPRxw8lRt0ns2SOPPGLpEDqnpgryToI4QmDfjmVvi36XaDYjo6CiT/vbRcRRRPaJyHrz9lAR2SEix0VklYh0+Uoqa+gO1XpAffleVWuOZe+5i+u6e4zo5K7ZjIzCCsL7dqTMb4CjjW4/DTyrlBoBFAC/6MpO3dzcyMvL0wne1qk6oyumpsLoinHuuWNTKUVeXh5ubl3vgtTdMppNqKmtI6u4ss9a7iISASwAngTuFWOg9RzgBnOVt4BHgJc6u++IiAjS09PR00vauPJ8qCo1hjsWZdDKpHNd5ubmRkRERJe318ldswmZRZXU1qm+bLk/B9wH1M8KEogxEXyNeTsdaLG8n4jcDtwOMHjw4GbLnZ2dG66M1GzU1r/Dpsdhxh9gyoOWjqZFultGswn1FzD1RctdRC4HspVSe7qyvZ4f2M4dWG0k9lHXwpy/WjqaVumWu2YTGi5g6puW+zRgoYhcBrgBPsDzgJ+IOJmt91Ynf9fsWPI2WHcnRE6HRS9axZDH1uiWu2YTMouM5B7m2/vJXSn1gFIqQik1BLgO2KSUWgZsBpaYqzWeGF7rD3KOwcpl4D8Ernu31ya27ik6uWs24XRRJf4ezri7WHQM8Z8wTq4ex+iDf82SwWh9qDQbViwxyvYuWw3u/paOqF26W0azCZmFFYT2Qav9XEqpLcAW8++TwMQ+D0KzrKpyeP86I8H//DOj5W4DdMtdswmZRZWE+emyA1ofq6uFj26DjL2w5HUIH2/piDpMJ3fNJmQWVVqk5a71c1/8GRLWw6VPQ+xllo6mU3Ry16xeeVUNRRXVDPTVLXetD21/CXa8DJPvhEm/tHQ0naaTu2b1ThdWAuhuGa3vHF0PGx6A2Mvh4icsHU2X6OSuWb2sIiO5624ZrU+k74YPbzX61xe/ajVVHjurW8ldRH4nIodF5JCIvC8ibj1ZOU/TAE734Rh3rZ/LPwXvLQXvAXD9SnDp+KQw1qbLyV1EwoF7gAlKqfMBR4wLPnqkcp6m1cs0u2UG+Fr3RSOajSvPhxXXGOV7l30IXrZdOqK73TJOgLuIOAEeQCZG5bw15vK3gCu7+RhaP5dVXEGQlyuuTrb59VizATVnjatPC1PguvcgaISlI+q2Lid3pVQG8HcgFSOpFwF76GDlPE3rqNOFeoy71ovq6mDtnZD6PVz5EkROtXREPaI73TL+wCJgKBAGeALzO7H97SKyW0R267rWWlsyiyr0vKla79n0OBxaA3MfhlFL2l/fRnSnW+Yi4JRSKkcpVQ18hFFNz8/spoE2KufpsqhaRyiljOn1+nYGJq2/2PMmbHsGxt8M039n6Wh6VHeSeyowWUQ8zFlq5gJH0JXztB5UXFlDWVVtn86dqvUTx7+G9ffCiIvgsn9YdfneruhOn/sOjBOne4GD5r5eQVfO03pQfR33MJ3ctZ6UdRA+WA4hcXDNm+BofzUUu/WMlFIPAw+fc7eunKf1mNOFOrlrPawoA1ZcC64+sOwDcPVufxsbZH8fV5pdabiASY+W0XpCZTG8dy2cLYFbNoBPmKUj6jU6uWtWLaOwAhcnB4I89QVMWjfVVsPq5ZB91JhwY+D5lo6oV+nkrlm104WVhPm64eBgXye7tD6mFHx2L5zYBAtfgBFzLR1Rr9OFwzSrllFQrvvbte779h+w922Y8QeIv8nS0fQJndw1q2ZcnaqTu9YNB1YbFyqNuhbm/NXS0fQZndw1q1VdW8eZEp3ctW5I3gbr7oTI6bDoRbsby94Wndw1q5VVVIlSEK5HymhdkZMIK28wJrRe+g449a+T8jq5a1YrraAcgHA/262prVlIaTasWAKOLsbIGI8AS0fU5/RoGc1qpeQZyX1IkE7uWidUlRsTbpTmwM8/M1ru/ZBuuWtWKyWvHGdH6fPp9cwZxXaKyI/mTGOPmvfrWcasXV2tMUXe6X2w5DVjqrx+Sid3zWql5JUxKMADx74f434WmKOUGgOMBeaLyGT0LGPW74u/QOJncOnTELvA0tFYlE7umtVKzitnSKBnnz+uMpSaN53NH4WeZcy6bX8JdrwEk++ESb+0dDQWp5O7ZpWUUqTklREZaJn+dhFxFJH9QDbwFXCCDs4ypieisYCj62HDAxB7OVz8hKWjsQo6uWtWKbe0ivKqWou03AGUUrVKqbEYE85MBGI7sa2eiKYvpe8x+tnDx8PiV8FBz7ULOrlrViolrwzAYi33ekqpQowJaKbQwVnGtD6Uf8qo8ugVAtevBBc9sqqeTu6aVUo2h0FGWqDlLiLBIuJn/u0OzAOOomcZsy7l+bDiGqirgZ99CF76W1Jjepy7ZpVS88pwdBBLTa8XCrwlIo4YDaAPlFLrReQIsFJEngD2oWcZs5yas7DqZ1CYAjetg6AoS0dkdXRy16zSsTOlDA7wwMWp779cKqUOAONauF/PMmYNlIJ1d0HKd3D1axA51dIRWSXdLaNZpYMZRZwf7mvpMDRrtOlxOLga5j4Mo5a0v34/pZO7ZnUKyqrIKKzg/DAfS4eiWZs9bxm12cffDNN/Z+lorJpO7prVOXy6GEC33LWmkr6G9b+D4XPhsn/0q/K9XaGTu2Z1DmYUAXCebrlr9bIOGvOfhsTBtW+Boz5d2B6d3LU+tTkxm/GPf8X857by9ZEzLa5z6HQREf7u+HnoulwaUJQBK64FN19Y9gG4els6Ipugk7vWZ6pr63j80yO4OTtSXVvHb1ftJy2/vNl6hzOKGKW7ZDSAymLjIqWzJXDDB+ATZumIbIZO7lqfWbkrjZO5ZTy68DzeumUiAvxu1X7q6lTDOql55STnlTNusJ/F4tSsRG01rL4Zso8aXTEDz7d0RDZFJ3etz7z7QwrjBvsxd2QIEf4ePHhFHLtTClj3409X8X+0Lx0RuHy0bqH1a0rBZ/fCiY1wxXMwYq6lI7I53UruIuInImtEJEFEjorIFBEJEJGvRCTJ/O3fU8Fqtiuv9CyJZ0qYFzcAMUc5LImPYHSEL0/9N4GyszUopfh4XwZThgXqSbH7u2//AXvfhhl/gPibLB2NTepuy/15YINSKhYYg1F/435go1IqCtho3tb6uZ2n8gGYNDSw4T4HB+HhK+LILjnL3e/tZfWedFLyyrlqXIuVdLX+4sBq40KlUdfCnL9aOhqb1eXkLiK+wEzM+hpKqSqzgt4ijIkMQE9ooJl2nMrH3dmR0RFNT5SOjwzgyStHsTkxh/vWHCB2oDeXjQq1UJSaxSVvg3V3QuR0WPSiHsveDd0ZLDoUyAHeEJExwB7gN8AApVSmuU4WMKB7IWr2YPvJPCYM8cfZsXl74oZJg/F0daSyupar4yNwamEdrR/IOQYrlxkTWl/3Lji5Wjoim9ad5O4ExAO/VkrtEJHnOacLRimlRES1tLGI3A7cDjB48OBuhKFZu8LyKhKySrh8dOst8kVjdVdMv1aaDSuuBkdnWLYa3PWpuu7qThMpHUhXSu0wb6/BSPZnRCQUwPyd3dLGeraa/uOIWU5g3GD9htVaUFUG7y2F0hy4YZXRcte6rcvJXSmVBaSJSIx511zgCPAJxkQGoCc00ICkbGOu6agBXhaORLM6dbXw4W1weh9c/R9jqjytR3S3QMOvgRUi4gKcBH6OObmBiPwCSAGu7eZjaDbu2JkSfN2dCfbSfajaOb74CyR+BvOfhpGXWzoau9Kt5K6U2g9MaGGRvuJAa5CUXUpUiFfD+HZNA2D7S7DjJZh8J0y+w9LR2B09LEHrdcezS3WXjNbU0fWw4QGIvRwufsLS0dglndy1XpVXepb8sipGhOhKfpopfQ98eCuEx8PiV8HB0dIR2SWd3LVeVX8yNVq33DWAgmR4fyl4hcD1q8DFw9IR2S2d3LVelXSmBIAo3XLXyvPh3SVGtcdla8BLD4HuTXo6E61Xncgpw8vViQE+eqRMv1ZzFlb9DApT4KZ1EBxt6YjsnlW33B9ed4hHPz1s6TC0bkjJKyMy0EOPlOnP6upg7Z2Q8h1c+RJETrV0RP2CVSf3vLIqPj+YiVItVjDQbEBKfjmRgbbVryoig0Rks4gcEZHDIvIb835dzrorNj8Bh9bA3Idg1BJLR9NvWHVynzo8iDPFZzmVW2bpULQuqKtTpOdXMCjAtpI7UAP8XikVB0wG7hKROHQ5687b85ZRmz1+OUy/19LR9CtWndynDDdqf39/Is/CkWhdkVVcSVVtHYNtLLkrpTKVUnvNv0sw5ikIR5ez7pzjX8P638HwubDgH7p8bx+z6uQ+JNCDgT5u/HBSJ3dblGpOfh0Z4GnhSLpORIYA44Ad6HLWHZd1ED5YDiFxxvynjs6WjqjfserkLiJMGR7I9hN5ut/dBtUnd1trudcTES/gQ+C3SqnixsuUcUC2Ws5aRHaLyO6cnJw+iNTKFGXAimvB1QeWfQCuehisJVh1cgeYPCyAvLIqTup+d5uTmleOo4MQ6udm6VA6TUScMRL7CqXUR+bdupx1eyqL4b1r4Wyxkdh99ETnlmL1yT0u1JiW7VhWiYUj0TorNb+ccD/3FmdfsmZijNt8DTiqlHqm0SJdzrottdWw+mbIPgrXvg0DR1k6on7N6t91I0K8EIFjZ0otHYrWSSn55bbaJTMNuBGYIyL7zZ/LgKeAeSKSBFxk3tYAlILPfg8nNsIVz8EIXRjW0qz+ClV3F0cGB3hw7IxuuduatPxyLjlvoKXD6DSl1DagtaEdOmu15Nt/wN63YMbvIf4mS0ejYQMtdzDqkujkbltKz9aQX1bFoAB3S4ei9bYDq2HT4zDqGpjzoKWj0Uw2kdyjB3hxKreMqpo6S4eidVBGQQUAg/xtsltG66jkbbDuToicBov+pceyWxGbSO4xA72pqVMk5+kRM7YizRwGGeGvW+52K+cYrFxmTGh93Qpw0sXhrIlNJPf6crGJesSMzUgvMJK7DZYe0DqiNBtWLDEuTlq2Gtx1mR1rY/UnVAGGBXviID/VBtesX3pBBW7ODgR6ulg6FK2nVZXD+9cZCf7nnxktd83q2ERyd3N2JNzfneS8ckuHonVQWkE5Ef661K/dqauFj26DjL1GV0z4eEtHpLXCJpI7wJBAT1J0n7vNSC+oYJDub7c/X/wFEtbD/KchdoGlo9HaYBN97mDUJ0nJ1y13W5FeUEGEHiljX7a/BDtegkm/gsl3WDoarR02k9wjAz0oLK+mqLza0qFo7SiurKaoolqPcbcnR9fDhgcg9nK45ElLR6N1gA0ld6NsbEq+7pqxdun5xhh33XK3E+l74MNbITweFr8KDo6WjkjrABtK7kaiSNEnVa1e/TBIPcbdDhQkw/tLwSsErl8FLvoD21Z0O7mLiKOI7BOR9ebtoSKyQ0SOi8gqEemRsXD1Baj0SVXrV1/HXV+dauPK8+HdJUa1x2VrwKuflS+2cT3Rcv8NxjRk9Z4GnlVKjQAKgF/0wGPg4eJEiLerbrnbgNT8crzdnPDz0LPv2Kyas7DqZ1CYAte9B8HRlo5I66RuJXcRiQAWAP8xbwswB1hjrtKj80xGBnro5G4DUvLKiQzUY9xtVl0drLsLUr6DK1+CIdMsHZHWBd1tuT8H3AfUV/QKBAqVUjXm7XSMiYV7xOAAT31C1Qak5pfb9Lyp/d7mJ+Dgapj7EIxaYulotC7qcnIXkcuBbKXUni5u3+l5JiMDPThTfJbK6tquPKTWB2rrFOkF5QwO1P3tNmnPW0Zt9vjlMP1eS0ejdUN3Wu7TgIUikgysxOiOeR7wE5H6K18jgIyWNu7KPJP146bTzXKymvU5XVhBda0iUhcMsz3HN8L638HwubDgH7p8r43rcnJXSj2glIpQSg0BrgM2KaWWAZuB+u9yPTrPZP2ImTR9parVqh8po1vuNibrIHywHELi4Nq3jGqPmk3rjXHufwLuFZHjGH3wr/XUjuuH1qUV6ORurepPeNvo3Kn9U1EGrLgWXL1h2QfGb83m9UjhMKXUFmCL+fdJYGJP7Pdcwd6uuDo5kKpHzFitlPwynB2FUF99AZNNqCyG966FsyVwy3/BJ8zSEWk9xGaqQgKICIMCPHTL3Yql5pUzyN8DRwfdX2v1aqth9c2QfdRosQ8cZemItB5kU8kdjK/7qfn6hKq1OpVbxpAgPQzS6ikFn90LJzbCwhdgxEWWjkjrYTZTW6beIH930vPLUUpZOhTtHNW1dZzIKSV6gO6ztXrbnoG9b8OMP0D8TZaORusFtpfcAzwoOVtDUYUu/dtXVu9OY19qQbvrpeSVUV2riB7g1QdRaV12YDVsfAxGXQNz/mrpaLReYpPJHX4acqf1rvd2pPLHNQe45uUfWLEjpc11E7NKAWy+5S4ir4tItogcanRfgIh8JSJJ5m/bnBE6+TtYdydETodF/9Jj2e2YzSX3wTq595mjmcU8/MkhZkQFMXVEEA+uPdTmSKXEMyU4CIwIsfmW+5vA/HPuux/YqJSKAjaat21LzjFYeQP4RcJ174KTq6Uj0nqRzSV3Xde976zdb1xc/M/rxvG/V4/GQYTXvzvV6vrHskoYEuiJm7NtT+aglNoK5J9z9yKMQnjQwwXx+kRpNqxYYlyc9LM14G6bXzy0jrO55O7h4sQAH1dO5eoCYr1tS0IOFwwJwN/ThYG+biwcG8YHu9NanerwWHYJUfbb3z5AKZVp/p0FDGhtxa7UTepVVeXw/nVGgr9+FfgPsXREWh+wueQOxpR7etKO3pVRWEHimRJmx4Q03Hfr9GGUV9WyZm96s/Urq2tJzi0jxsb72ztCGUO1Wh2u1ZW6Sb2mrhY+ug0y9sKS1yBivGXj0fqMTSb3IYEenMrV3TK9aUtiNgCzY39KTnFhPowK9+Xjfc2T+9HMYuoUxIb69FmMfeyMiIQCmL+zLRxPx3z5V0hYD/OfgtgFlo5G60O2mdyDPMktPUvp2Zr2V9a65JvEHML93Bke3LSb5apx4RzKKCbpTEmT+7cl5SICk4cF9mWYfekTjEJ40MMF8XrN9pdh+/+DSb+CyXdYOhqtj9lmcg80roBM1v3uveZgRhEXDPFvNpvSwrFhODoIH+1rWsn52+O5nBfmQ4Bnj0yZa1Ei8j7wAxAjIuki8gvgKWCeiCQBF5m3rdfR9bDhfoi9HC550tLRaBZg08ldj5jpHQVlVWQWVTKyhS6WIC9XZscEs3p3WsOkKaVna9ibUsD0EfYxgbJS6nqlVKhSytksa/2aUipPKTVXKRWllLpIKXXuaBrrkb4HPrwVwuNh8avgYNujl7SuscnkXj8cMlmfVO0VRzOLAaOPvSW3TBtKbmkV68yhkjtO5lFTp5gRFdRnMWqtKEiG95eCVwhcvxJcdOnl/somk7unqxMh3q4d6papqa3jgY8OsujFbeSXVfVBdLbviJncW2q5A0wZHkhcqA+vfnuKmto6VuxIxd3ZkfGReuy0RZXnw7tLjGqPP/vQSPBav2WTyR1gaJAnx3NK21xHKcVvV+3n/Z2pHD5dzC1v7qKiSs+/2p4jmcWEeLsS5NXyFYwiwh2zhnM8u5SLnvmGTQnZ/PGSGJu/eMmm1ZyFVT+DwhS47j0IirJ0RJqF2WxyHxnqQ2JWCXV1rVeH3JdWyPoDmfxmbhQvXD+O/WmFDV0JWuuOZpa02iVTb+GYMJ6+ehSniyq5OG4AP582pG+C05qrq4N1d0HKd3DlSzBkmqUj0qyAzdVzrzcy1JvyqlpS88tbrR/+7vYUPF0cuW3mMDxdHAn3c+fro9lcN3FwH0drO6pq6jieXcKsmPZPji69YDDz4gbi4+bUbFSN1oc2PwkHV8Pch2DUkvbX1/oFm265w08n/85VUFbF+gOZLI6PwMvVSD4XjQxh2/GchlEeWnOnco2yvbEDO3alaYCnC06ONnsY2b49b8G3fzdqsk+/19LRaFbEZt+V0QO8cZDWk/va/RlU1dSxbPJPrfS5IwdQWV3H9ydy+ypMm3PSPI9x7sVLmhU6/jWs/x0MnwsLntHle7UmbDa5uzk7MizYi6NZJS0u/+xAJrEDvYkd+FPf8aRhAXi6OPLVEdu4ctwSTpojkIbqqfKsW9Yh+OBmCImDa98yqj1qWiM2m9zB6JppqeWeVVTJ7pQCFowKbXK/q5MjFwwN6NCsQv3ViZxSBvq44elqs6dj7F9RBqy4Bly94YZVxm9NO4eNJ3dv0gsqmk25999DRmXWy0aHNtvmvDAfkrJLdb97K07lljEsWLfarVZlMby3FM6WwLLV4Btu6Yg0K2XTyX38YOOime+PN+1D//TH08QO9G6x3/i8MF9q6xTHzrTcndOfKaU4mVOmu2SsVW01rPk5ZB8xumIGnm/piDQrZtvJPdIfPw9nvjp6puG+pDMl7E0tZHF8yy2a88zx24dPt3witj/LL6uiqKKaYfpkqvVRCj671ziJevmzMGKupSPSrJxNJ3cnRwfmxISwOSGbWvNiplW70nByEBbHR7S4zeAAD7zdnDh8uqgvQ7UJ9bNbDdMtd+vz7T9g79sw4/cwfnn762v9XpeTu4gMEpHNInJERA6LyG/M+/t0lvi5IwdQUF7N3tQCKqtr+WhfBvPiBrR56XxcqI9uubfgZI6Z3HWfu3U5sBo2PQ6jroE5D1o6Gs1GdKflXgP8XikVB0wG7hKROPp4lviZ0UG4ODnw9H8TuG/NAfLLqrhxSmSb25wX5ktCZklDa18znMwtw9lRiPDXlQStRvJ3sO5OiJwGi/6lx7JrHdbl5K6UylRK7TX/LgGOAuH08Szx3m7OPHPtGPanFfLJj6f5/bxopg5vu/TsyFBvKqpr9Tys5ziVW8rgAA8cHXQCsQq5SbDyBmNC6+tWgFPL30Y1rSU9MphZRIYA44AddGKW+J5y+egwAjxdSMgs6VABqxEhxgnDkzll+uRhI8m55XqkjLUozYZ3rzYuTlq2Gtx1OWWtc7p9QlVEvIAPgd8qpZp0ZLc1S7yI3C4iu0Vkd05OTnfDYOrwIG6ZPrRDBazqE/qJdkoG9yd1dYrkvLKGWa40C6oqh/evMxL89auMlrumdVK3kruIOGMk9hVKqY/Muzs0S7xS6hWl1ASl1ITg4L6dns3X3Zlgb1eOZ+vkXi+ruJKzNXWtVtjU+khdLXx0G2TshSWvQcR4S0ek2ajujJYR4DXgqFLqmUaLbGKW+OHBnrrl3kiyriljHb74CySsh/n/A7ELLB2NZsO603KfBtwIzBGR/ebPZdjILPHDg704kVOG0XOknTJPLuuWuwVtfxl2vASTfgWTf2XpaDQb1+UTqkqpbUBrHdxWf/nc8GAviiqqySuranVMfH+SnFuGq5MDoT5ulg6lf0r4DDbcD7GXwyVPWjoazQ7Y9BWq3THcHDFzwg773ROyijs9neCp3HKGBHrioIdB9r30PbDmFxAeD4tfBQc9F63Wff22rutw8yrMEzllTBoWaOFoes4rW0/wvxsSqalTODoIl48O69B2yXllDa+J1joRmQ88DzgC/1FKda/bsSAZ3l8KXiHGyBgXfQGZ1jP6bcs9zNcdN2cHuzqpmlt6lqc3JDIzOpgxEb78de0hsosr292upraO1LxyhgbpMf9tERFH4F/ApUAccL15VXbXlOfDu0uMao/L1oBX344a0+xbv03uDg7CkEDPhmJZ9uDzg5nU1inumx/DM0vHUlxRzTvbU9rdLjW/nKrauoaLu7RWTQSOK6VOKqWqgJUYV2R3Sk1tHf/4/ABFby5FFabAde9BcHSPB6v1b/02uYNRIOukHbXc1+0/TcwAY2rB4cFeTBoayGcHM9sdEZRknneI0sm9PeFAWqPb6eZ9TbR3gd7x7GKitt+Pb/ZO7qu5g19+68r7O1PJLKrovci1fqff9rkDDAvy4ovDZ6iqqcPFqeOfcwVlVXi7OeHkaD2fjWn55exJKeCPl8Q03HfZ6FAeXHuIxDMlTeaSPVf9xVzDdXLvEUqpV4BXACZMmNDskzW27iQxjttJOu9enB0XczAhmy8OG3MSxA705sKYYGbHhDA+0h9nKzrGNNvSv5N7sCe1dYrU/PIOd0mczCllwT+3EerrxkNXxDErJqSXo+yYbeZsVPPPH9hw3/zzBvLwukN8fjCr3eQe5uuGl543tT0ZwKBGtyPM+zonPB65YxtRISP5mwhKKZKyS9mckM2WxBxe33aKf39zEm9XJ6aNCGJ2bDAXRocw0FcPU9U6rl+/m+uvxjyVW9ah5K6U4q9rD+HkKCBw14q97PrrRXi4WP5l/DGtEF935yYTbQR7u3LBkAC+PJzFvfNa79NNyi5hxAA9yXIH7AKiRGQoRlK/DrihS3sa8NN5WBEheoA30QO8+eWFwyk9W8O2pFy+OWYk+w2HswCjVT87NoRZ0cHE61a91g7LZyULqi8gZvS7t1+8csOhLL4/kccTV55PVIgXS1/ZzheHs7hqXMuzPvWl/WmFjBnk16xw2qyYEJ7ekEB2cSUhLVygVFenOJFdxsSJ9jMctLcopWpE5G7gC4yhkK8rpQ739ON4uTox//yBzD9/IEopEs+UsCUxhy2J2by69SQvbTmBt6sTM6KDmBUdwoUxwQzQF59p5+jXyd3X3ZkgL5eGGYjas27/aQb6uHHDxMEARPi789HeDIsn97KzNRw7U8LF5w1stmxGVBBPbzC6bVqaejCjsIKK6lqiBuj+9o5QSn0OfN5XjycixA70IXagD3dcOJySymq+O57LlsQcNidm8/lBo1UfF+rDrJhgZseGMG6Qn1WdD9Iso18ndzC6ZjoyHLKyupZvjuWwZHxEw1Wci+MjeGFTEplFFYT6uvd2qK06mFFEnYJxg/yaLYsL9SHA04VtSS0n96TsEgA9DNJGeLs5M//8UOafH4pSioSsEjYnGt03/956kv+35QQ+bk7MiApmVkwwF8YEE+KtW/X9Ub9P7sODvfjqyJl219uWlEtFdS3z4n7qvlkwKpR/bkxiW1Iu10wY1MbWvWt/WiEAY1pI7g4OwtThgXx7PBelVLNumx/TinAQGBna+glXzTqJCCNDfRgZ6sOds0ZQXFnNtqRctpjJ/rODxpw554X5MDsmhFkxwYzVrfp+o98n96gB3qzclUZu6dk2C4h9eSQLb1cnJjcqVRAV4oW3mxN7Uwstmtx/TCtkcIAHAZ4uLS6fGRXM+gOZJGSVNEvie1MLiB7grUfK2AEfN2cuGxXKZaOMVv2RzGK2JObwTWIOL31zghc3H8fHzYmZ0cHMignhwuhggr110Tx71e/f0THmKJFjZ0paTe5KKbYk5jAzJrjJeHgHB2HsID/2pRZ0+fH3pxXyzFfHKK2s5v5LRzJxaECn95GYVUJcGy3vmdHGZe2bE7ObJPe6OsX+tEKuGNOx+jOa7RARzgvz5bwwX+6aPYKiikat+mM5rD9gtOpHhfsyKybYbNX76/lz7Ui/T+7RA42+5mNZJa1OrH0yt4zskrNMa2F5/GB//rkpiZLKarzdnDv9+E/99yiHTxfj6CD87fOjfHzn1A5NFVivsrqW5LyyNhP0QF83zg/3YdPRbO6cNaLh/hM5pZRU1rTYV6/ZF193ZxaMDmXB6FDq6upb9Ub3zb82H+eFTcfx83BmRlQws2OCmRkdrEth27h+n9yDvVzx93Am8UzrZQh+OJEHwJThzYcLxkf6oxQcSC9i2oiWPxxacyijiO0n8/nzZbF4uDjx17WH+OFEHlM7sZ/j2aXUKYgZ2PY49TmxA3hxUxL5ZVUN3Tf7UgsbnoPWfzg4COeH+3J+uC93z4misLyKb5OMETjfHMvm0x9PAzA6wpdZ0cHMig1hTISfbtXbmH6f3OsvIDl2pqTVdX44mcdAHzeGBDYvxzrWbPXuTSnodHJ/bdspPF0cuW7iYFwcHfjnxiRe+uZEp5J7QpYRd3vJfW5sCP/cmMQ3x7Ibhm7uTS3A192ZoXpS7H7Nz8OFK8aEccWYMOrqFIdPF5sjcLJ5cfNx/rnpOP5mq35WTDAXRgcTqFv1Vq/fJ3cwEuPHezNaHE2ilGLHyTymjwhqsbvE192Z4cGe/Jhe2KnHrK6t44vDWVw5LhwfsztncXwE//n2JGVna/Ds4AnOY2dKcHFyIDKg7Trgo8J9GeDjyod7jHH5FVW1bDicxfQRQXqCDq2Bg4MwKsKXURG+3DPXaNV/c8w4KfvNsRw++fE0IjA63JdZ5gic0bpVb5V0cgeiB3hTcraGzKJKwvyajldPyi4lt7SqxS6ZenFhvuxN6dxJ1QPphZRX1TKjUSt9+oggXv7mBDtP5TM7tmM1axKzShgR7NXu8DYHB+EX04fyt88T2JdaQEJWCYXl1dw0JbJTcWv9i5+HC4vGhrNobDh1dYqDGUXG1bLHsvnnpiSe35hEgKcLM6OCmBUTwszo4FZHbWl9Syd3furSOHK6uFly35ZkFORq7WQrwMhQbz798TTFldUNrfD21PfjN54FasIQf1ycHNh2PLdTyX1qGx88jS2bFMn/23KCx9YfobC8mrhQny6NztH6JwcHYcwgP8YM8uM3F0WRX1bFt0k5Zl99Dmv3G636MRF+DePqR4X76m+GFqKTO0aXhbOjsCsln4vimtaY2XY8lyGBHgxqo9tjpFlxMSGzpMPJcvvJfGIHejdp5bg5O3LBEH++Mys8tqeovJqs4kqi2+lvr+fp6sTvL47hoXWHUAqev25sp0bmaFpjAZ5NW/UHMooaRuA8t/EYz359jEBPFy6MNq6UnRkVjL9u1fcZndwxkuqYCD92nspvcn9VTR3bT+ZxdQuX7TcWG2ok14Ss4g4l97M1texOyed6s0ZNY9NGBPG/GxLJLqls97LxY2bpgJhOVHS8cXIk14yPoKZO6QuXtB5Tf83H2EF+/PaiaPLLqth6zCh2tjkxm4/2ZeAgxgCE+r7688N0q7436Xe36YKhAby69STlVTUNJXz3phZQXlXL9Ki2R68M9HHD192Zo5mtj7hp7GB6EZXVdU2udq03xbxvT3IBl44KbXM/9SN8Otpyr+fm7Nip9TWtswI8XbhyXDhXjguntk7xY3qhebVsNs9+fYxnvjpGkJdLw9WyM6OC8PPQrfqepJO7aeLQAF7acoJ9qYUNQxq3HsvB0UHaPJkK9TU+vEnIKu7QY9XXgokf3Hx8eVyYDy6ODuxPK2w/uWeV4OXqRJiexEGzYo4OQvxgf+IH+3PvvGhyS8+arfocNiVk89Feo1U/brA/s2OMZB8X6qNb9d2kk7tpfKQ/DgI7TuUzbUQQtXWKtfsymDo8sEMnSWMH+vDB7jTq6lS7B+WB9CLCfN1arOvh6uTIyDAf9pkfAG1JPFNC1AAv3W+u2ZQgL1cWx0ewOD6CWrMExjdmWYS/f3mMv395jCAvVy6MDmZ2bDAzRgTj69H5q7/7O53cTT5uzowZ5MenP57m13NGsCUxh9NFlTx0RVz7G2OMmCmvqiU1v5whQW1fFHQgvZBREb6tLh83yI9Vu9Koqa1rc4jjsTOlXBzX/iQjmmatHB2E8ZH+jI/0596LY8gpMVv1x3L4+ugZPtybbrb8/RqKnZ0X5qMbNB3QK8ldROYDz2PMVvMfpdRTvfE4Pe1XFw7n9nf2sHJXGl8cymKAjysXjexY8qyfozQhq6TN5F5UXk1yXnmbVSTHDfbjze+TSTxTwnlhLX8I5JaeJb+siig9PZ5mR4K9Xbl6fARXj4+gprauoa9+S2IO//dFIv/3RSIh3karflZMCNOjgvB11636lvR4chcRR+BfwDwgHdglIp8opY709GP1tHlxAxg32I8H1x4C4L75MR2ufR09wBsRY8RM40mqz3Uwowgw6na0pr6kwf60wlaT+7Gszo+U0TRb4uTowPjIAMZHBvD7i2PILqnkm0SjVf/F4SxW7zFa9eMH+3NhTDCzY0IYGeqtW/Wm3mi5TwSOK6VOAojISmARYPXJXUR4bOH5/L8tx7lqXHiHW+0A7i6ODA30JKGdETMHMgoBGB3u1+o69bXZ96cWsmxSy1eQJjaMlNEzKGn9Q4i3G9dMGMQ1EwZRU1vHvrTChnH19a36AT5mX31MCNOigjp8UaE96o3kHg6kNbqdDkzqhcfpFaMifHnpZ+O7tG1sqDdHTrc9YuZAWhGRgR5tniASEcYN8mNvG3XiD58uJtDThWBdwEnrh5wcHbhgSAAXDAngj5fEkl1cyRazBs5/D2Xxwe50nByE+Ej/hqtlYwf2r1a9xU6oisjtwO0Agwc3v5jHFsUO9OG/h7LaLPx1IL2QCUPav9ApPtKfjQnZFJZXtTj+92B6EaMjfPvVwapprQnxcePaCYO41mzV7039qVX/9IYEnt6QwEAft4aJSaaNCOrS/Au2pDeSewbQ+GxhhHlfE0qpV4BXACZMmKB6IY4+FzvQG6WMi4vGtTCGPbukktNFlW32t9cbN9gPgH1phcyOaVpnpryqhqTsEi45T4+U0bRzOTk6MHFoABOHBnDf/FjOFNf31Wfz2YFMVu5Kw8lBmDDEn1kxIcyOCSHaDocU90Zy3wVEichQjKR+HXBDLzyO1amfwu5oZsvJ/UCacTK1pYmszzUmwg8HgX0pBc2S+9HMYuoUjIpofz+a1t8N8HHj2gsGce0Fg6iurWNPSoE5Aiebp/6bwFP/TSDM140LzQuopo0IsovSHD3+DJRSNSJyN/AFxlDI15VSh3v6caxRhL87vu7OHMwoBJp3NR1IL8TRQTgvrPX5Tut5ujoRO9CHveZsSU330/6IG61rROQa4BFgJDBRKbW70bIHgF8AtcA9SqkvLBKk1mXOjg5MHhbI5GGB3H9pLFlFlQ3dN5/+mMn7O9NwdhQmRAYwO9ZI9lEhttmq75WPJ6XU58DnvbFvayZSP2F2YYvL96cXERXi1VC7pj3xkX6s3Xe62cVMB9OLCPZ2ZYCPLjvQCw4Bi4F/N75TROIwvoWeB4QBX4tItFKqtu9D1HrKQF83rps4mOsmDqaqxmzVH8vmm8Qc/vZ5An/7PIFwP3ejVR9t9NV3dCIdS7ONKG3IuMF+PL8xidKzNU2+2imlOJBeyPzzWh8Df64pw4J4d3sqe1MLm1Sb3J9eyKhw3WrvDUqpo0BLLbVFwEql1FnglIgcxxj2+0PfRqj1FhcnB6YMD2TK8EAeuHQkpwsr+MasbLluXwbv7UjFxdGBC4b6MyvaGIEzwopb9Tq597Bxg80Js9MKm8yFejy7lMLy6oYTpR0xMzoIJwdhY8KZhuSemlfOyZwybmihXLDWq8KB7Y1up5v3aXYqzM+d6ycO5nqzVb87Jb+hr/7Jz4/y5OdHCfdzZ5Z5AdXUEYEd/lbeF6wnEjsx1jzJue+c5P6tOaNTZybR9nZzZtKwADYezeaBS0cC8OWRLAAu6cQ3AK0pEfkaaOkF/ItSal0P7N/uhvn2dy5ODkwdHsTU4UH8+bKRZBRWGLXqE3L4eF8GK8xW/cShAeZwyxCGB3tatFWvk3sP8/VwZliwZ7N+923Hcxka5EmEf9sTWZ9rbuwAHlt/hJS8MiIDPfnicBYjQ33anBlKa5tS6qIubNahIb7m/u1umK/WVLifO8smRbJsUqQx+U5yAZsTjMqWT3x2lCc+O0qEv3vDBVRThvd9q14n914wIdKf/x7KorK6Fjdnxw7P6NSSi0Yayf3tH1L45YXD2J1SwG/mRvVC1Fo7PgHeE5FnME6oRgE7LRuSZg1cnRyZNiKIaSOC+CuQXlDOZnNikjV70nlnewouTg5MGhpgjqsPZmhQ77fqdXLvBZePDuOD3elsTsjm0lGh7OvgjE4tGRzowbJJg3lt2yk2J2TjKMLlo9uexEPrOhG5CngBCAY+E5H9SqlLlFKHReQDjBpJNcBdeqSM1pIIfw9unBzJjZONVv3OUz/11T++/giPrzfqR9X31U8eFoi7S8/PjqaTey+YOjyQYG9X1u7P4NJRoazandZwJr4r/rJgJD+czCOzsJJXl09gRIiuBNlblFIfAx+3suxJ4Mm+jUizZa5OjsyICmZGVDAPXh5HWn65Oa9sDh/sTuPtH4xW/eRhgQ2zUA1tZz6IjtLJvRc4OTqwcEwYb/+QzOcHM/l4Xwa3zxzW5Qp1Hi5OrLljKuVVNZ3us9c0zXoMCvDgxilDuHHKECqrjVb95kRjXP2jnx7h0U+PEBno0dBXP3lYYJfnPNbJvZdcP3EQ7+1I5c4Ve/HzcObOWSO6tb8ATxcCPPUEwppmL9ycHZkZHczM6GC4whjmvDkxmy2J2azclcqb3yfj6uTA1eMj+NtVozq9f53ce8mIEG+++eMs3v4hhbGD/PRsMZqmtWlwoAfLpw5h+VSjVb/9ZB5bEnMI8elaWW+d3HtRiI8bf7gkxtJhaJpmY9ycHZkVE8Ksc4oGdkbH5pDTNE3TbIpO7pqmaXZIJ3dN0zQ7pJO7pmmaHdLJXdM0zQ7p5K5pmmaHdHLXNE2zQzq5a5qm2SFRyvLlpkUkB0hpZXEQkNuH4fQle35uYD3PL1IpFWyJB9bHtl2ypufW6rFtFcm9LSKyWyk1wdJx9AZ7fm5g/8+vu+z59dHPzfJ0t4ymaZod0sld0zTNDtlCcn/F0gH0Int+bmD/z6+77Pn10c/Nwqy+z13TNE3rPFtouWuapmmdpJO7pmmaHbLa5C4i80UkUUSOi8j9lo6nu0RkkIhsFpEjInJYRH5j3h8gIl+JSJL529/SsXaViDiKyD4RWW/eHioiO8z/4SoR0fMEYl/Htj6urfe4tsrkLiKOwL+AS4E44HoRibNsVN1WA/xeKRUHTAbuMp/T/cBGpVQUsNG8bat+AxxtdPtp4Fml1AigAPiFRaKyInZ4bOvj2kqPa6tM7sBE4LhS6qRSqgpYCSyycEzdopTKVErtNf8uwThYwjGe11vmam8BV1okwG4SkQhgAfAf87YAc4A15io2+9x6mF0d2/q4tt7nZq3JPRxIa3Q73bzPLojIEGAcsAMYoJTKNBdlAQMsFVc3PQfcB9SZtwOBQqVUjXnbrv6H3WC3x7Y+rq2LtSZ3uyUiXsCHwG+VUsWNlyljXKrNjU0VkcuBbKXUHkvHolmGPq6tj5OlA2hFBjCo0e0I8z6bJiLOGG+AFUqpj8y7z4hIqFIqU0RCgWzLRdhl04CFInIZ4Ab4AM8DfiLiZLZy7OJ/2APs7tjWx7V1/v+steW+C4gyz0q7ANcBn1g4pm4x++peA44qpZ5ptOgTYLn593JgXV/H1l1KqQeUUhFKqSEY/6tNSqllwGZgibmaTT63XmBXx7Y+rq33uVllcjc/Ee8GvsA4QfOBUuqwZaPqtmnAjcAcEdlv/lwGPAXME5Ek4CLztr34E3CviBzH6Kt8zcLxWJwdHtv6uLbS41qXH9A0TbNDVtly1zRN07pHJ3dN0zQ7pJO7pmmaHdLJXdM0zQ7p5K5pmmaHdHLXNE2zQzq5a5qm2aH/D3bF9YLlPCLNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "prediction_trained = model.predict(test_x)\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax1.set_title('Test data')\n",
    "ax1.plot(test_x, test_y)\n",
    "ax2.set_title('Prediction on test set')\n",
    "ax2.plot(test_x, prediction_untrained, test_x, prediction_trained)\n",
    "ax2.legend(['Untrained prediction', 'Trained prediction'], loc='upper left')\n",
    "plt.savefig('test_and_prediction_on_test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
